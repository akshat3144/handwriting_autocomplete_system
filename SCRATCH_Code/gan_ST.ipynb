{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe2b58f",
   "metadata": {},
   "source": [
    "## Parse The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37ebab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def parse_iam_words(root_dir=\"iam_words/words\", words_file=\"iam_words/words_new.txt\"):\n",
    "    records = []\n",
    "    with open(words_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\") or len(line.strip()) == 0:\n",
    "                continue\n",
    "\n",
    "            parts = line.strip().split()\n",
    "            word_id, ok_flag = parts[0], parts[1]\n",
    "            if ok_flag != \"ok\":  # skip bad segmentations\n",
    "                continue\n",
    "\n",
    "            writer_id = word_id[:3]\n",
    "            form_id = word_id[:8]  # a01-000u\n",
    "            image_path = Path(root_dir) / writer_id / form_id / f\"{word_id}.png\"\n",
    "            if not image_path.exists():\n",
    "                continue\n",
    "\n",
    "            word_text = parts[-1]\n",
    "            records.append({\n",
    "                \"writer_id\": writer_id,\n",
    "                \"word_id\": word_id,\n",
    "                \"image_path\": str(image_path),\n",
    "                \"text\": word_text\n",
    "            })\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "746f0527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  writer_id         word_id                                       image_path  \\\n",
      "0       a01  a01-000u-00-00  iam_words\\words\\a01\\a01-000u\\a01-000u-00-00.png   \n",
      "1       a01  a01-000u-00-01  iam_words\\words\\a01\\a01-000u\\a01-000u-00-01.png   \n",
      "2       a01  a01-000u-00-02  iam_words\\words\\a01\\a01-000u\\a01-000u-00-02.png   \n",
      "3       a01  a01-000u-00-03  iam_words\\words\\a01\\a01-000u\\a01-000u-00-03.png   \n",
      "4       a01  a01-000u-00-04  iam_words\\words\\a01\\a01-000u\\a01-000u-00-04.png   \n",
      "\n",
      "   text  \n",
      "0     A  \n",
      "1  MOVE  \n",
      "2    to  \n",
      "3  stop  \n",
      "4   Mr.  \n",
      "\n",
      " Columns:\n",
      "Index(['writer_id', 'word_id', 'image_path', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = parse_iam_words()\n",
    "print(df.head())\n",
    "print(\"\\n Columns:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26a737e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id status  gray     x    y    w   h  tag transcription\n",
      "0  a01-000u-00-00     ok   154   408  768   27  51   AT             A\n",
      "1  a01-000u-00-01     ok   154   507  766  213  48   NN          MOVE\n",
      "2  a01-000u-00-02     ok   154   796  764   70  50   TO            to\n",
      "3  a01-000u-00-03     ok   154   919  757  166  78   VB          stop\n",
      "4  a01-000u-00-04     ok   154  1185  754  126  61  NPT           Mr.\n",
      "38305 valid words\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "with open(\"iam_words/words_new.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\") or len(line.strip()) == 0:\n",
    "            continue\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 9:\n",
    "            continue  # skip broken lines\n",
    "        \n",
    "        try:\n",
    "            # Expected format: id ok graylevel x y w h tag transcription\n",
    "            word_id = parts[0]\n",
    "            status = parts[1]\n",
    "            gray = int(parts[2])\n",
    "            x, y, w, h = map(int, parts[3:7])\n",
    "            tag = parts[7]\n",
    "            transcription = \" \".join(parts[8:])  # handles multi-token words like \"M Ps\"\n",
    "\n",
    "            data.append({\n",
    "                \"id\": word_id,\n",
    "                \"status\": status,\n",
    "                \"gray\": gray,\n",
    "                \"x\": x, \"y\": y, \"w\": w, \"h\": h,\n",
    "                \"tag\": tag,\n",
    "                \"transcription\": transcription\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # skip lines that don't match format\n",
    "            # (there are a few weird ones in IAM)\n",
    "            # print(\"Skipping:\", line.strip(), \"Error:\", e)\n",
    "            continue\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[df[\"status\"] == \"ok\"].reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "print( len(df), \"valid words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56e13210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class IAMWordStyleDataset(Dataset):\n",
    "    def __init__(self, df, words_root, target_size=(64, 256), transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.words_root = words_root\n",
    "        self.target_size = target_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        word_id = row[\"id\"]\n",
    "        target_text = row[\"transcription\"]\n",
    "\n",
    "        # reconstruct file path like words/a01/a01-000u/a01-000u-00-01.png\n",
    "        subdir = os.path.join(word_id[:3], f\"{word_id.split('-')[0]}-{word_id.split('-')[1]}\")\n",
    "        img_path = os.path.join(self.words_root, subdir, f\"{word_id}.png\")\n",
    "\n",
    "        # load target image\n",
    "        try:\n",
    "            target_img = Image.open(img_path).convert(\"L\")\n",
    "        except FileNotFoundError:\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "        # extract writer id (e.g. 'a01')\n",
    "        writer_id = word_id.split(\"-\")[0]\n",
    "\n",
    "        # get random style sample from same writer (different word ideally)\n",
    "        same_writer_df = self.df[self.df[\"id\"].str.startswith(writer_id)]\n",
    "        # try to avoid choosing same word as style sample\n",
    "        same_writer_df = same_writer_df[same_writer_df[\"id\"] != word_id]\n",
    "        if same_writer_df.empty:\n",
    "            same_writer_df = self.df[self.df[\"id\"].str.startswith(writer_id)]\n",
    "        \n",
    "        style_row = same_writer_df.sample(1).iloc[0]\n",
    "        style_word_id = style_row[\"id\"]\n",
    "        style_text = style_row[\"transcription\"]\n",
    "\n",
    "        style_subdir = os.path.join(style_word_id[:3], f\"{style_word_id.split('-')[0]}-{style_word_id.split('-')[1]}\")\n",
    "        style_path = os.path.join(self.words_root, style_subdir, f\"{style_word_id}.png\")\n",
    "\n",
    "        try:\n",
    "            style_img = Image.open(style_path).convert(\"L\")\n",
    "        except FileNotFoundError:\n",
    "            style_img = target_img\n",
    "\n",
    "        # pad images to target size with white padding instead of stretching\n",
    "        style_img = self._pad_image(style_img)\n",
    "        target_img = self._pad_image(target_img)\n",
    "        \n",
    "        # convert to tensor\n",
    "        style_img = T.ToTensor()(style_img)\n",
    "        target_img = T.ToTensor()(target_img)\n",
    "        \n",
    "        # apply additional transforms if any\n",
    "        if self.transform:\n",
    "            style_img = self.transform(style_img)\n",
    "            target_img = self.transform(target_img)\n",
    "        \n",
    "        return {\n",
    "            \"style_img\": style_img,\n",
    "            \"style_text\": style_text,\n",
    "            \"target_img\": target_img,\n",
    "            \"target_text\": target_text\n",
    "        }\n",
    "    \n",
    "    def _pad_image(self, img):\n",
    "        \"\"\"Pad image to target size maintaining aspect ratio with white padding\"\"\"\n",
    "        target_h, target_w = self.target_size\n",
    "        w, h = img.size\n",
    "        \n",
    "        # calculate scale to fit within target size\n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        \n",
    "        # resize maintaining aspect ratio\n",
    "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        \n",
    "        # create white background\n",
    "        padded = Image.new(\"L\", (target_w, target_h), 255)\n",
    "        \n",
    "        # paste resized image centered\n",
    "        paste_x = (target_w - new_w) // 2\n",
    "        paste_y = (target_h - new_h) // 2\n",
    "        padded.paste(img, (paste_x, paste_y))\n",
    "        \n",
    "        return padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9af217aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style text:  remains\n",
      "Target text: MOVE\n",
      "torch.Size([1, 64, 256]) torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "dataset = IAMWordStyleDataset(df, \"iam_words/words\")\n",
    "item = dataset[1]\n",
    "\n",
    "print(\"Style text: \", item[\"style_text\"])\n",
    "print(\"Target text:\", item[\"target_text\"])\n",
    "print(item[\"style_img\"].shape, item[\"target_img\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90df70fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image shapes - Style: torch.Size([1, 64, 256]), Target: torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualize style and target images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# style image\n",
    "axes[0].imshow(item[\"style_img\"].squeeze(), cmap='gray')\n",
    "axes[0].set_title(f'Style Image\\nText: \"{item[\"style_text\"]}\"')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# target image\n",
    "axes[1].imshow(item[\"target_img\"].squeeze(), cmap='gray')\n",
    "axes[1].set_title(f'Target Image\\nText: \"{item[\"target_text\"]}\"')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nImage shapes - Style: {item['style_img'].shape}, Target: {item['target_img'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb0370",
   "metadata": {},
   "source": [
    "## Build Character Vocabulary and Text Encoder\n",
    "\n",
    "First, we need to build a vocabulary from all unique characters in the dataset and create a text encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build character vocabulary\n",
    "def build_vocab(df):\n",
    "    \"\"\"Build character-to-index mapping from dataset\"\"\"\n",
    "    all_chars = set()\n",
    "    for text in df['transcription']:\n",
    "        all_chars.update(text)\n",
    "    \n",
    "    # Add special tokens\n",
    "    vocab = {\n",
    "        '<PAD>': 0,\n",
    "        '<SOS>': 1,\n",
    "        '<EOS>': 2,\n",
    "        '<UNK>': 3\n",
    "    }\n",
    "    \n",
    "    # Add all characters\n",
    "    for char in sorted(all_chars):\n",
    "        vocab[char] = len(vocab)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(df)\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"Sample characters: {list(vocab.items())[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab, max_len=20):\n",
    "    \"\"\"Convert text to indices with padding\"\"\"\n",
    "    indices = [vocab.get(char, vocab['<UNK>']) for char in text]\n",
    "    # Truncate or pad\n",
    "    if len(indices) > max_len:\n",
    "        indices = indices[:max_len]\n",
    "    else:\n",
    "        indices = indices + [vocab['<PAD>']] * (max_len - len(indices))\n",
    "    return indices\n",
    "\n",
    "# Test encoding\n",
    "sample_text = \"hello\"\n",
    "encoded = text_to_indices(sample_text, vocab)\n",
    "print(f\"Text: {sample_text}\")\n",
    "print(f\"Encoded: {encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab1ee4",
   "metadata": {},
   "source": [
    "## Improved Architecture - ScrabbleGAN Style\n",
    "\n",
    "Now let's implement a more sophisticated architecture inspired by ScrabbleGAN with:\n",
    "- Multi-word style context (up to 3 consecutive words)\n",
    "- Modulated residual blocks with AdaIN\n",
    "- Patch-based discriminator\n",
    "- Multi-stage training strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198b7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "class ImprovedIAMWordStyleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Enhanced dataset that uses up to 3 consecutive words as style context.\n",
    "    Word ID format: a02-000-02-03.png means writer a02, form 000, line 02, word 03\n",
    "    \"\"\"\n",
    "    def __init__(self, df, words_root, vocab, target_size=(64, 256), max_text_len=20, \n",
    "                 max_style_words=3, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.words_root = words_root\n",
    "        self.vocab = vocab\n",
    "        self.target_size = target_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.max_style_words = max_style_words\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create index for fast lookup: (writer, form, line) -> list of word indices\n",
    "        self.line_index = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            word_id = row[\"id\"]\n",
    "            parts = word_id.split(\"-\")\n",
    "            if len(parts) >= 4:\n",
    "                writer = parts[0]\n",
    "                form = parts[1]\n",
    "                line = parts[2]\n",
    "                word_num = parts[3]\n",
    "                key = (writer, form, line)\n",
    "                if key not in self.line_index:\n",
    "                    self.line_index[key] = []\n",
    "                self.line_index[key].append((idx, int(word_num)))\n",
    "        \n",
    "        # Sort each line's words by word number\n",
    "        for key in self.line_index:\n",
    "            self.line_index[key].sort(key=lambda x: x[1])\n",
    "\n",
    "    def _parse_word_id(self, word_id):\n",
    "        \"\"\"Parse word_id to extract writer, form, line, word_num\"\"\"\n",
    "        parts = word_id.split(\"-\")\n",
    "        if len(parts) >= 4:\n",
    "            return parts[0], parts[1], parts[2], int(parts[3])\n",
    "        return None, None, None, None\n",
    "\n",
    "    def _get_consecutive_style_words(self, writer, form, line, exclude_word_num=None):\n",
    "        \"\"\"Get up to max_style_words consecutive words from the same line\"\"\"\n",
    "        key = (writer, form, line)\n",
    "        if key not in self.line_index:\n",
    "            return []\n",
    "        \n",
    "        words_in_line = self.line_index[key]\n",
    "        \n",
    "        # Filter out the target word if specified\n",
    "        if exclude_word_num is not None:\n",
    "            words_in_line = [(idx, wn) for idx, wn in words_in_line if wn != exclude_word_num]\n",
    "        \n",
    "        if not words_in_line:\n",
    "            return []\n",
    "        \n",
    "        # Randomly select a starting position\n",
    "        if len(words_in_line) <= self.max_style_words:\n",
    "            selected = words_in_line\n",
    "        else:\n",
    "            start_idx = random.randint(0, len(words_in_line) - self.max_style_words)\n",
    "            selected = words_in_line[start_idx:start_idx + self.max_style_words]\n",
    "        \n",
    "        return [idx for idx, _ in selected]\n",
    "\n",
    "    def _load_image(self, word_id):\n",
    "        \"\"\"Load image from word_id\"\"\"\n",
    "        parts = word_id.split(\"-\")\n",
    "        if len(parts) < 2:\n",
    "            return None\n",
    "        \n",
    "        writer = parts[0]\n",
    "        form = f\"{parts[0]}-{parts[1]}\"\n",
    "        \n",
    "        img_path = os.path.join(self.words_root, writer, form, f\"{word_id}.png\")\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            return img\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _pad_image(self, img):\n",
    "        \"\"\"Pad image to target size maintaining aspect ratio\"\"\"\n",
    "        target_h, target_w = self.target_size\n",
    "        w, h = img.size\n",
    "        \n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        \n",
    "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        \n",
    "        padded = Image.new(\"L\", (target_w, target_h), 255)\n",
    "        \n",
    "        paste_x = (target_w - new_w) // 2\n",
    "        paste_y = (target_h - new_h) // 2\n",
    "        padded.paste(img, (paste_x, paste_y))\n",
    "        \n",
    "        return padded\n",
    "\n",
    "    def _concatenate_images_horizontal(self, images):\n",
    "        \"\"\"Concatenate multiple images horizontally\"\"\"\n",
    "        if not images:\n",
    "            return Image.new(\"L\", self.target_size, 255)\n",
    "        \n",
    "        # Calculate total width\n",
    "        total_width = sum(img.size[0] for img in images)\n",
    "        max_height = max(img.size[1] for img in images)\n",
    "        \n",
    "        # Create concatenated image\n",
    "        concat = Image.new(\"L\", (total_width, max_height), 255)\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            concat.paste(img, (x_offset, 0))\n",
    "            x_offset += img.size[0]\n",
    "        \n",
    "        return concat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        word_id = row[\"id\"]\n",
    "        target_text = row[\"transcription\"]\n",
    "        \n",
    "        # Parse target word info\n",
    "        writer, form, line, word_num = self._parse_word_id(word_id)\n",
    "        \n",
    "        # Load target image\n",
    "        target_img = self._load_image(word_id)\n",
    "        if target_img is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        \n",
    "        # Get consecutive style words from same writer and line\n",
    "        if writer and form and line:\n",
    "            style_indices = self._get_consecutive_style_words(writer, form, line, exclude_word_num=word_num)\n",
    "        else:\n",
    "            style_indices = []\n",
    "        \n",
    "        # If no consecutive words found, use random word from same writer\n",
    "        if not style_indices:\n",
    "            same_writer_df = self.df[self.df[\"id\"].str.startswith(writer) if writer else False]\n",
    "            same_writer_df = same_writer_df[same_writer_df[\"id\"] != word_id]\n",
    "            if not same_writer_df.empty:\n",
    "                style_row = same_writer_df.sample(1).iloc[0]\n",
    "                style_indices = [same_writer_df.index[same_writer_df[\"id\"] == style_row[\"id\"]].tolist()[0]]\n",
    "            else:\n",
    "                style_indices = [idx]  # fallback to same image\n",
    "        \n",
    "        # Load style images and texts\n",
    "        style_images = []\n",
    "        style_texts = []\n",
    "        for s_idx in style_indices:\n",
    "            s_row = self.df.iloc[s_idx]\n",
    "            s_img = self._load_image(s_row[\"id\"])\n",
    "            if s_img is not None:\n",
    "                style_images.append(s_img)\n",
    "                style_texts.append(s_row[\"transcription\"])\n",
    "        \n",
    "        # Concatenate style images\n",
    "        if len(style_images) > 1:\n",
    "            style_img_concat = self._concatenate_images_horizontal(style_images)\n",
    "        elif len(style_images) == 1:\n",
    "            style_img_concat = style_images[0]\n",
    "        else:\n",
    "            style_img_concat = target_img\n",
    "        \n",
    "        # Concatenate style texts\n",
    "        style_text = \" \".join(style_texts) if style_texts else target_text\n",
    "        \n",
    "        # Pad images\n",
    "        style_img_concat = self._pad_image(style_img_concat)\n",
    "        target_img = self._pad_image(target_img)\n",
    "        \n",
    "        # Convert to tensor (normalize to [-1, 1] for GAN)\n",
    "        style_img_tensor = T.ToTensor()(style_img_concat) * 2 - 1\n",
    "        target_img_tensor = T.ToTensor()(target_img) * 2 - 1\n",
    "        \n",
    "        # Apply additional transforms\n",
    "        if self.transform:\n",
    "            style_img_tensor = self.transform(style_img_tensor)\n",
    "            target_img_tensor = self.transform(target_img_tensor)\n",
    "        \n",
    "        # Encode text to indices\n",
    "        style_text_indices = text_to_indices(style_text[:self.max_text_len*3], self.vocab, self.max_text_len*3)\n",
    "        target_text_indices = text_to_indices(target_text, self.vocab, self.max_text_len)\n",
    "        \n",
    "        return {\n",
    "            \"style_img\": style_img_tensor,\n",
    "            \"style_text\": style_text,\n",
    "            \"style_text_indices\": torch.tensor(style_text_indices, dtype=torch.long),\n",
    "            \"target_img\": target_img_tensor,\n",
    "            \"target_text\": target_text,\n",
    "            \"target_text_indices\": torch.tensor(target_text_indices, dtype=torch.long),\n",
    "            \"writer_id\": writer if writer else \"unknown\"\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "print(\" Improved dataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImprovedStyleEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced style encoder with writer classification capability for pretraining.\n",
    "    Extracts both global style features and can be pretrained on writer ID classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, style_dim=512, num_writers=None):\n",
    "        super(ImprovedStyleEncoder, self).__init__()\n",
    "        \n",
    "        # Convolutional feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            # Input: (1, 64, 256)\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3),  # (64, 32, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),  # (64, 16, 64)\n",
    "            \n",
    "            self._make_layer(64, 128, 2),   # (128, 8, 32)\n",
    "            self._make_layer(128, 256, 2),  # (256, 4, 16)\n",
    "            self._make_layer(256, 512, 2),  # (512, 2, 8)\n",
    "        )\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # Style embedding\n",
    "        self.style_fc = nn.Sequential(\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, style_dim)\n",
    "        )\n",
    "        \n",
    "        # Writer classification head (for pretraining)\n",
    "        self.num_writers = num_writers\n",
    "        if num_writers is not None:\n",
    "            self.writer_classifier = nn.Sequential(\n",
    "                nn.Linear(style_dim, 512),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, num_writers)\n",
    "            )\n",
    "    \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks):\n",
    "        \"\"\"Create a residual layer\"\"\"\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1))\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        for _ in range(num_blocks - 1):\n",
    "            layers.append(ResidualBlock(out_channels))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, style_img, return_writer_logits=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256)\n",
    "            return_writer_logits: whether to return writer classification logits\n",
    "        Returns:\n",
    "            style_embed: (batch, style_dim)\n",
    "            writer_logits: (batch, num_writers) if return_writer_logits=True\n",
    "        \"\"\"\n",
    "        features = self.features(style_img)  # (batch, 512, 2, 8)\n",
    "        pooled = self.gap(features).view(features.size(0), -1)  # (batch, 512)\n",
    "        style_embed = self.style_fc(pooled)  # (batch, style_dim)\n",
    "        \n",
    "        if return_writer_logits and self.num_writers is not None:\n",
    "            writer_logits = self.writer_classifier(style_embed)\n",
    "            return style_embed, writer_logits\n",
    "        \n",
    "        return style_embed\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Basic residual block\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "print(\" Improved Style Encoder defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaIN(nn.Module):\n",
    "    \"\"\"\n",
    "    Adaptive Instance Normalization\n",
    "    Modulates features based on style vector\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, style_dim):\n",
    "        super(AdaIN, self).__init__()\n",
    "        self.norm = nn.InstanceNorm2d(num_features, affine=False)\n",
    "        \n",
    "        # Style modulation: predict scale and bias from style\n",
    "        self.style_scale = nn.Linear(style_dim, num_features)\n",
    "        self.style_bias = nn.Linear(style_dim, num_features)\n",
    "    \n",
    "    def forward(self, x, style):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, channels, H, W)\n",
    "            style: (batch, style_dim)\n",
    "        \"\"\"\n",
    "        # Normalize\n",
    "        normalized = self.norm(x)\n",
    "        \n",
    "        # Get style modulation parameters\n",
    "        scale = self.style_scale(style).unsqueeze(2).unsqueeze(3)  # (batch, channels, 1, 1)\n",
    "        bias = self.style_bias(style).unsqueeze(2).unsqueeze(3)\n",
    "        \n",
    "        # Apply modulation\n",
    "        return scale * normalized + bias\n",
    "\n",
    "\n",
    "class ModulatedResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with style modulation via AdaIN\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, style_dim):\n",
    "        super(ModulatedResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.adain1 = AdaIN(channels, style_dim)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.adain2 = AdaIN(channels, style_dim)\n",
    "    \n",
    "    def forward(self, x, style):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.adain1(out, style)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.adain2(out, style)\n",
    "        \n",
    "        out = out + residual\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class ImprovedGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    ScrabbleGAN-style generator with modulated residual blocks.\n",
    "    Uses AdaIN to inject style information throughout the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, text_dim=256, style_dim=512, num_res_blocks=6, output_channels=1):\n",
    "        super(ImprovedGenerator, self).__init__()\n",
    "        \n",
    "        # Combine text embeddings (style_text + target_text)\n",
    "        self.text_fusion = nn.Sequential(\n",
    "            nn.Linear(text_dim * 2, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "        \n",
    "        # Initial projection from combined embeddings to spatial features\n",
    "        combined_dim = style_dim + 256  # style + fused text\n",
    "        self.initial_projection = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 256 * 4 * 16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.encoder = nn.ModuleList([\n",
    "            # (256, 4, 16) -> (256, 4, 16)\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                nn.InstanceNorm2d(256),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Modulated residual blocks (content transformation with style injection)\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ModulatedResBlock(256, style_dim) for _ in range(num_res_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.decoder = nn.Sequential(\n",
    "            # (256, 4, 16) -> (256, 8, 32)\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (256, 8, 32) -> (128, 16, 64)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (128, 16, 64) -> (64, 32, 128)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (64, 32, 128) -> (32, 64, 256)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # (32, 64, 256) -> (1, 64, 256)\n",
    "            nn.Conv2d(32, output_channels, kernel_size=7, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, style_embed, style_text_embed, target_text_embed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_embed: (batch, style_dim) - from style image encoder\n",
    "            style_text_embed: (batch, text_dim) - from text encoder on style text\n",
    "            target_text_embed: (batch, text_dim) - from text encoder on target text\n",
    "        Returns:\n",
    "            generated_img: (batch, 1, 64, 256)\n",
    "        \"\"\"\n",
    "        batch_size = style_embed.size(0)\n",
    "        \n",
    "        # Fuse text embeddings\n",
    "        text_combined = torch.cat([style_text_embed, target_text_embed], dim=1)\n",
    "        text_fused = self.text_fusion(text_combined)  # (batch, 256)\n",
    "        \n",
    "        # Combine with style\n",
    "        combined = torch.cat([style_embed, text_fused], dim=1)  # (batch, style_dim + 256)\n",
    "        \n",
    "        # Project to spatial features\n",
    "        features = self.initial_projection(combined)  # (batch, 256*4*16)\n",
    "        features = features.view(batch_size, 256, 4, 16)  # (batch, 256, 4, 16)\n",
    "        \n",
    "        # Encode\n",
    "        for layer in self.encoder:\n",
    "            features = layer(features)\n",
    "        \n",
    "        # Apply modulated residual blocks (inject style at each block)\n",
    "        for res_block in self.res_blocks:\n",
    "            features = res_block(features, style_embed)\n",
    "        \n",
    "        # Decode to image\n",
    "        generated = self.decoder(features)  # (batch, 1, 64, 256)\n",
    "        \n",
    "        return generated\n",
    "\n",
    "\n",
    "print(\" Improved Generator with AdaIN and modulated residual blocks defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchGAN discriminator that outputs a grid of predictions.\n",
    "    Each prediction judges a patch of the input as real/fake.\n",
    "    Also conditioned on target text.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=2, text_dim=256, num_layers=4):\n",
    "        super(PatchDiscriminator, self).__init__()\n",
    "        \n",
    "        # Text conditioning pathway\n",
    "        self.text_encoder = nn.Sequential(\n",
    "            nn.Linear(text_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Convolutional layers (PatchGAN)\n",
    "        layers = []\n",
    "        \n",
    "        # First layer (no normalization)\n",
    "        layers.append(nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        # Middle layers\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, num_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            layers.append(nn.Conv2d(64 * nf_mult_prev, 64 * nf_mult, \n",
    "                                   kernel_size=4, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(64 * nf_mult))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # Calculate feature map size after convolutions\n",
    "        # Input: (2, 64, 256) -> after 4 layers of stride-2: (512, 4, 16)\n",
    "        self.feature_channels = 64 * nf_mult\n",
    "        self.feature_h = 64 // (2 ** num_layers)\n",
    "        self.feature_w = 256 // (2 ** num_layers)\n",
    "        \n",
    "        # Text conditioning via spatial broadcast and concatenation\n",
    "        self.text_spatial = nn.Sequential(\n",
    "            nn.Linear(512, self.feature_h * self.feature_w),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Final classification layers\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.feature_channels + 1, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, style_img, target_or_gen_img, target_text_embed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256)\n",
    "            target_or_gen_img: (batch, 1, 64, 256)\n",
    "            target_text_embed: (batch, text_dim)\n",
    "        Returns:\n",
    "            validity_map: (batch, 1, H, W) - patch-wise predictions\n",
    "        \"\"\"\n",
    "        batch_size = style_img.size(0)\n",
    "        \n",
    "        # Concatenate style and target/generated images\n",
    "        img_pair = torch.cat([style_img, target_or_gen_img], dim=1)  # (batch, 2, 64, 256)\n",
    "        \n",
    "        # Extract image features\n",
    "        img_features = self.conv_layers(img_pair)  # (batch, feature_channels, feature_h, feature_w)\n",
    "        \n",
    "        # Process text embedding\n",
    "        text_features = self.text_encoder(target_text_embed)  # (batch, 512)\n",
    "        text_spatial = self.text_spatial(text_features)  # (batch, feature_h * feature_w)\n",
    "        text_spatial = text_spatial.view(batch_size, 1, self.feature_h, self.feature_w)\n",
    "        \n",
    "        # Concatenate image and text features spatially\n",
    "        combined = torch.cat([img_features, text_spatial], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        validity_map = self.final_conv(combined)  # (batch, 1, feature_h, feature_w)\n",
    "        \n",
    "        return validity_map\n",
    "\n",
    "\n",
    "print(\" Patch-based Discriminator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283bf06a",
   "metadata": {},
   "source": [
    "## Multi-Stage Training Strategy\n",
    "\n",
    "We'll implement a 3-stage training approach:\n",
    "1. **Stage 1**: Pretrain style encoder on writer classification\n",
    "2. **Stage 2**: Pretrain generator with content/reconstruction loss only\n",
    "3. **Stage 3**: Full GAN training with gradual adversarial loss introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Pretrain Style Encoder on Writer Classification\n",
    "\n",
    "def pretrain_style_encoder(style_encoder, train_loader, device, num_epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Pretrain style encoder to classify writers.\n",
    "    This helps it learn meaningful style representations.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE 1: Pretraining Style Encoder on Writer Classification\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    style_encoder.train()\n",
    "    optimizer = torch.optim.Adam(style_encoder.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create writer ID mapping\n",
    "    writer_ids = train_loader.dataset.df['id'].apply(lambda x: x.split('-')[0]).unique()\n",
    "    writer_to_idx = {w: i for i, w in enumerate(sorted(writer_ids))}\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Stage 1 Epoch {epoch}/{num_epochs}\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            style_img = batch['style_img'].to(device)\n",
    "            writer_labels = torch.tensor([writer_to_idx[w] for w in batch['writer_id']], \n",
    "                                        dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward with writer classification\n",
    "            style_embed, writer_logits = style_encoder(style_img, return_writer_logits=True)\n",
    "            \n",
    "            # Classification loss\n",
    "            loss = criterion(writer_logits, writer_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track accuracy\n",
    "            _, predicted = writer_logits.max(1)\n",
    "            correct += predicted.eq(writer_labels).sum().item()\n",
    "            total += writer_labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = 100. * correct / total\n",
    "        print(f\"Epoch {epoch}: Loss = {avg_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "    \n",
    "    print(\" Style encoder pretraining completed!\\n\")\n",
    "    return style_encoder\n",
    "\n",
    "\n",
    "print(\" Stage 1 training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Pretrain Generator with Content Loss Only\n",
    "\n",
    "def pretrain_generator(text_encoder, style_encoder, generator, train_loader, device, \n",
    "                      num_epochs=20, lr=0.0002):\n",
    "    \"\"\"\n",
    "    Pretrain generator with only content/reconstruction loss.\n",
    "    No adversarial loss yet - just learn to generate readable text.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE 2: Pretraining Generator with Content Loss\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    text_encoder.train()\n",
    "    style_encoder.eval()  # Keep style encoder frozen\n",
    "    generator.train()\n",
    "    \n",
    "    # Optimizer for text encoder + generator\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(text_encoder.parameters()) + list(generator.parameters()),\n",
    "        lr=lr, betas=(0.5, 0.999)\n",
    "    )\n",
    "    \n",
    "    l1_loss = nn.L1Loss()\n",
    "    l2_loss = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        total_loss = 0\n",
    "        total_l1 = 0\n",
    "        total_l2 = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Stage 2 Epoch {epoch}/{num_epochs}\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            style_img = batch['style_img'].to(device)\n",
    "            target_img = batch['target_img'].to(device)\n",
    "            style_text_indices = batch['style_text_indices'].to(device)\n",
    "            target_text_indices = batch['target_text_indices'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Encode\n",
    "            with torch.no_grad():\n",
    "                style_embed = style_encoder(style_img)\n",
    "            \n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            \n",
    "            # Generate\n",
    "            fake_img = generator(style_embed, style_text_embed, target_text_embed)\n",
    "            \n",
    "            # Content losses\n",
    "            loss_l1 = l1_loss(fake_img, target_img)\n",
    "            loss_l2 = l2_loss(fake_img, target_img)\n",
    "            \n",
    "            # Combined loss (weighted)\n",
    "            loss = loss_l1 * 10.0 + loss_l2 * 1.0\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_l1 += loss_l1.item()\n",
    "            total_l2 += loss_l2.item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'L1': f'{loss_l1.item():.4f}',\n",
    "                'L2': f'{loss_l2.item():.4f}'\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_l1 = total_l1 / len(train_loader)\n",
    "        avg_l2 = total_l2 / len(train_loader)\n",
    "        print(f\"Epoch {epoch}: Total = {avg_loss:.4f}, L1 = {avg_l1:.4f}, L2 = {avg_l2:.4f}\")\n",
    "        \n",
    "        # Visualize every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            visualize_stage2_results(text_encoder, style_encoder, generator, \n",
    "                                    train_loader.dataset, device)\n",
    "    \n",
    "    print(\" Generator pretraining completed!\\n\")\n",
    "    return text_encoder, generator\n",
    "\n",
    "\n",
    "def visualize_stage2_results(text_encoder, style_encoder, generator, dataset, device, num_samples=4):\n",
    "    \"\"\"Visualize results during stage 2 training\"\"\"\n",
    "    text_encoder.eval()\n",
    "    style_encoder.eval()\n",
    "    generator.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples * 3))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i * len(dataset) // num_samples]  # Sample evenly\n",
    "            \n",
    "            style_img = sample['style_img'].unsqueeze(0).to(device)\n",
    "            style_text_indices = sample['style_text_indices'].unsqueeze(0).to(device)\n",
    "            target_text_indices = sample['target_text_indices'].unsqueeze(0).to(device)\n",
    "            target_img = sample['target_img']\n",
    "            \n",
    "            # Generate\n",
    "            style_embed = style_encoder(style_img)\n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            fake_img = generator(style_embed, style_text_embed, target_text_embed)\n",
    "            \n",
    "            # Convert to numpy\n",
    "            style_np = (style_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            target_np = (target_img.squeeze().numpy() + 1) / 2\n",
    "            fake_np = (fake_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(style_np, cmap='gray')\n",
    "            axes[i, 0].set_title(f\"Style: '{sample['style_text'][:20]}'\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(fake_np, cmap='gray')\n",
    "            axes[i, 1].set_title(f\"Generated: '{sample['target_text']}'\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(target_np, cmap='gray')\n",
    "            axes[i, 2].set_title(f\"Ground Truth: '{sample['target_text']}'\")\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    text_encoder.train()\n",
    "    generator.train()\n",
    "\n",
    "\n",
    "print(\" Stage 2 training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Full GAN Training with Gradual Adversarial Loss\n",
    "\n",
    "def train_gan_epoch(text_encoder, style_encoder, generator, discriminator,\n",
    "                    train_loader, optimizer_G, optimizer_D, device, epoch,\n",
    "                    lambda_content=100, lambda_adv=1.0, use_feature_matching=True):\n",
    "    \"\"\"\n",
    "    Train GAN for one epoch with careful D/G balancing.\n",
    "    \"\"\"\n",
    "    text_encoder.train()\n",
    "    style_encoder.eval()  # Keep frozen after pretraining\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_adv_loss = 0\n",
    "    epoch_g_content_loss = 0\n",
    "    epoch_d_real_acc = 0\n",
    "    epoch_d_fake_acc = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Stage 3 Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        batch_size = batch['style_img'].size(0)\n",
    "        \n",
    "        style_img = batch['style_img'].to(device)\n",
    "        target_img = batch['target_img'].to(device)\n",
    "        style_text_indices = batch['style_text_indices'].to(device)\n",
    "        target_text_indices = batch['target_text_indices'].to(device)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1, 4, 16).to(device)  # Patch labels\n",
    "        fake_labels = torch.zeros(batch_size, 1, 4, 16).to(device)\n",
    "        \n",
    "        # =================== Train Discriminator ===================\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Encode\n",
    "        with torch.no_grad():\n",
    "            style_embed = style_encoder(style_img)\n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            fake_img = generator(style_embed, style_text_embed, target_text_embed)\n",
    "        \n",
    "        # Real loss\n",
    "        real_validity = discriminator(style_img, target_img, target_text_embed)\n",
    "        d_real_loss = F.binary_cross_entropy(real_validity, real_labels)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_validity = discriminator(style_img, fake_img.detach(), target_text_embed)\n",
    "        d_fake_loss = F.binary_cross_entropy(fake_validity, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # Calculate discriminator accuracy\n",
    "        d_real_acc = ((real_validity > 0.5).float().mean().item())\n",
    "        d_fake_acc = ((fake_validity < 0.5).float().mean().item())\n",
    "        d_acc = (d_real_acc + d_fake_acc) / 2\n",
    "        \n",
    "        # =================== Train Generator ===================\n",
    "        # Only train G if D is not too strong (adaptive training)\n",
    "        train_generator = (d_acc < 0.85)  # If D is too good, skip G training\n",
    "        \n",
    "        if train_generator:\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Encode (with gradients this time)\n",
    "            style_embed = style_encoder(style_img)\n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            \n",
    "            # Generate\n",
    "            fake_img = generator(style_embed, style_text_embed, target_text_embed)\n",
    "            \n",
    "            # Adversarial loss\n",
    "            fake_validity = discriminator(style_img, fake_img, target_text_embed)\n",
    "            g_adv_loss = F.binary_cross_entropy(fake_validity, real_labels)\n",
    "            \n",
    "            # Content loss\n",
    "            g_content_loss = F.l1_loss(fake_img, target_img)\n",
    "            \n",
    "            # Feature matching loss (if enabled)\n",
    "            g_fm_loss = 0\n",
    "            if use_feature_matching:\n",
    "                # Extract features from discriminator for real and fake\n",
    "                with torch.no_grad():\n",
    "                    real_features = discriminator.conv_layers(torch.cat([style_img, target_img], dim=1))\n",
    "                fake_features = discriminator.conv_layers(torch.cat([style_img, fake_img], dim=1))\n",
    "                g_fm_loss = F.l1_loss(fake_features, real_features) * 10.0\n",
    "            \n",
    "            # Total generator loss\n",
    "            g_loss = (lambda_adv * g_adv_loss + \n",
    "                     lambda_content * g_content_loss + \n",
    "                     g_fm_loss)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "        else:\n",
    "            g_adv_loss = torch.tensor(0.0)\n",
    "            g_content_loss = torch.tensor(0.0)\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_adv_loss += g_adv_loss.item() if train_generator else 0\n",
    "        epoch_g_content_loss += g_content_loss.item() if train_generator else 0\n",
    "        epoch_d_real_acc += d_real_acc\n",
    "        epoch_d_fake_acc += d_fake_acc\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'D_loss': f'{d_loss.item():.4f}',\n",
    "            'D_acc': f'{d_acc:.3f}',\n",
    "            'G_adv': f'{g_adv_loss.item():.4f}' if train_generator else 'skip',\n",
    "            'G_cont': f'{g_content_loss.item():.4f}' if train_generator else 'skip'\n",
    "        })\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    return {\n",
    "        'd_loss': epoch_d_loss / n_batches,\n",
    "        'g_adv_loss': epoch_g_adv_loss / n_batches,\n",
    "        'g_content_loss': epoch_g_content_loss / n_batches,\n",
    "        'd_real_acc': epoch_d_real_acc / n_batches,\n",
    "        'd_fake_acc': epoch_d_fake_acc / n_batches\n",
    "    }\n",
    "\n",
    "\n",
    "print(\" Stage 3 GAN training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a355e26",
   "metadata": {},
   "source": [
    "## Initialize Improved Models and Dataset\n",
    "\n",
    "Now let's set up everything with the new architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Get number of unique writers for style encoder pretraining\n",
    "writer_ids = df['id'].apply(lambda x: x.split('-')[0]).unique()\n",
    "num_writers = len(writer_ids)\n",
    "print(f\"Number of unique writers: {num_writers}\")\n",
    "\n",
    "# Create improved dataset\n",
    "print(\"\\nCreating dataset...\")\n",
    "improved_dataset = ImprovedIAMWordStyleDataset(\n",
    "    df, \n",
    "    \"iam_words/words\", \n",
    "    vocab,\n",
    "    target_size=(64, 256),\n",
    "    max_text_len=20,\n",
    "    max_style_words=3\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(improved_dataset)}\")\n",
    "\n",
    "# Test dataset\n",
    "print(\"\\nTesting dataset...\")\n",
    "sample = improved_dataset[0]\n",
    "print(f\"Style image shape: {sample['style_img'].shape}\")\n",
    "print(f\"Target image shape: {sample['target_img'].shape}\")\n",
    "print(f\"Style text: '{sample['style_text'][:50]}...'\")\n",
    "print(f\"Target text: '{sample['target_text']}'\")\n",
    "print(f\"Writer ID: {sample['writer_id']}\")\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(\n",
    "    improved_dataset, \n",
    "    batch_size=16,  # Smaller batch size for more stable training\n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    "    drop_last=True  # Drop last incomplete batch\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader created with batch size: {train_loader.batch_size}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")\n",
    "print(\" Dataset ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521248ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize improved models\n",
    "\n",
    "print(\"Initializing models...\")\n",
    "\n",
    "# Text encoder (same as before, but we'll use it better)\n",
    "text_encoder = TextEncoder(\n",
    "    vocab_size=len(vocab), \n",
    "    embedding_dim=128, \n",
    "    hidden_dim=256,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "# Improved style encoder with writer classification capability\n",
    "style_encoder = ImprovedStyleEncoder(\n",
    "    input_channels=1,\n",
    "    style_dim=512,\n",
    "    num_writers=num_writers\n",
    ").to(device)\n",
    "\n",
    "# Improved generator with AdaIN and modulated residual blocks\n",
    "generator = ImprovedGenerator(\n",
    "    text_dim=256,\n",
    "    style_dim=512,\n",
    "    num_res_blocks=6,\n",
    "    output_channels=1\n",
    ").to(device)\n",
    "\n",
    "# Patch-based discriminator\n",
    "discriminator = PatchDiscriminator(\n",
    "    input_channels=2,\n",
    "    text_dim=256,\n",
    "    num_layers=4\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Model Parameters:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Text Encoder:     {count_parameters(text_encoder):>12,}\")\n",
    "print(f\"Style Encoder:    {count_parameters(style_encoder):>12,}\")\n",
    "print(f\"Generator:        {count_parameters(generator):>12,}\")\n",
    "print(f\"Discriminator:    {count_parameters(discriminator):>12,}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total:            {count_parameters(text_encoder) + count_parameters(style_encoder) + count_parameters(generator) + count_parameters(discriminator):>12,}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\"\\n All models initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94a0b0b",
   "metadata": {},
   "source": [
    "## Complete Training Pipeline\n",
    "\n",
    "Run all 3 stages sequentially with checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32225b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    # Stage 1: Style encoder pretraining\n",
    "    'stage1_epochs': 10,\n",
    "    'stage1_lr': 0.001,\n",
    "    \n",
    "    # Stage 2: Generator pretraining  \n",
    "    'stage2_epochs': 20,\n",
    "    'stage2_lr': 0.0002,\n",
    "    \n",
    "    # Stage 3: GAN training\n",
    "    'stage3_epochs': 100,\n",
    "    'stage3_lr_g': 0.0001,\n",
    "    'stage3_lr_d': 0.00005,\n",
    "    'lambda_content': 50,  # Start with lower content weight\n",
    "    'lambda_adv_start': 0.1,  # Start with low adversarial weight\n",
    "    'lambda_adv_end': 1.0,  # Gradually increase to 1.0\n",
    "    \n",
    "    # General\n",
    "    'checkpoint_dir': 'checkpoints_improved',\n",
    "    'save_interval': 5\n",
    "}\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in config.items():\n",
    "    print(f\"{key:25s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4d8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 1: Pretrain Style Encoder\n",
    "print(\"\\n\" + \" Starting Multi-Stage Training\" + \"\\n\")\n",
    "\n",
    "try:\n",
    "    style_encoder = pretrain_style_encoder(\n",
    "        style_encoder,\n",
    "        train_loader,\n",
    "        device,\n",
    "        num_epochs=config['stage1_epochs'],\n",
    "        lr=config['stage1_lr']\n",
    "    )\n",
    "    \n",
    "    # Save stage 1 checkpoint\n",
    "    torch.save({\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'vocab': vocab,\n",
    "        'config': config\n",
    "    }, os.path.join(config['checkpoint_dir'], 'stage1_style_encoder.pth'))\n",
    "    print(f\" Stage 1 checkpoint saved\\n\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Stage 1 interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error in Stage 1: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc475bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 2: Pretrain Generator\n",
    "\n",
    "try:\n",
    "    text_encoder, generator = pretrain_generator(\n",
    "        text_encoder,\n",
    "        style_encoder,\n",
    "        generator,\n",
    "        train_loader,\n",
    "        device,\n",
    "        num_epochs=config['stage2_epochs'],\n",
    "        lr=config['stage2_lr']\n",
    "    )\n",
    "    \n",
    "    # Save stage 2 checkpoint\n",
    "    torch.save({\n",
    "        'text_encoder': text_encoder.state_dict(),\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'generator': generator.state_dict(),\n",
    "        'vocab': vocab,\n",
    "        'config': config\n",
    "    }, os.path.join(config['checkpoint_dir'], 'stage2_generator.pth'))\n",
    "    print(f\" Stage 2 checkpoint saved\\n\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Stage 2 interrupted by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error in Stage 2: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99311b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 3: Full GAN Training with Gradual Adversarial Loss\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STAGE 3: Full GAN Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize optimizers for stage 3\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    list(text_encoder.parameters()) + list(generator.parameters()),\n",
    "    lr=config['stage3_lr_g'],\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "optimizer_D = torch.optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=config['stage3_lr_d'],\n",
    "    betas=(0.5, 0.999)\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'd_loss': [],\n",
    "    'g_adv_loss': [],\n",
    "    'g_content_loss': [],\n",
    "    'd_real_acc': [],\n",
    "    'd_fake_acc': []\n",
    "}\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, config['stage3_epochs'] + 1):\n",
    "        # Gradually increase adversarial loss weight\n",
    "        progress = epoch / config['stage3_epochs']\n",
    "        lambda_adv = config['lambda_adv_start'] + (config['lambda_adv_end'] - config['lambda_adv_start']) * progress\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{config['stage3_epochs']} | Adversarial weight: {lambda_adv:.3f}\")\n",
    "        \n",
    "        # Train one epoch\n",
    "        losses = train_gan_epoch(\n",
    "            text_encoder, style_encoder, generator, discriminator,\n",
    "            train_loader, optimizer_G, optimizer_D, device, epoch,\n",
    "            lambda_content=config['lambda_content'],\n",
    "            lambda_adv=lambda_adv,\n",
    "            use_feature_matching=True\n",
    "        )\n",
    "        \n",
    "        # Store history\n",
    "        for key in history.keys():\n",
    "            history[key].append(losses[key])\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nEpoch {epoch} Summary:\")\n",
    "        print(f\"  D Loss:       {losses['d_loss']:.4f}\")\n",
    "        print(f\"  D Real Acc:   {losses['d_real_acc']:.3f}\")\n",
    "        print(f\"  D Fake Acc:   {losses['d_fake_acc']:.3f}\")\n",
    "        print(f\"  G Adv Loss:   {losses['g_adv_loss']:.4f}\")\n",
    "        print(f\"  G Content:    {losses['g_content_loss']:.4f}\")\n",
    "        \n",
    "        # Visualize results\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"\\n Visualizing results...\")\n",
    "            visualize_stage2_results(text_encoder, style_encoder, generator, \n",
    "                                    train_loader.dataset, device, num_samples=4)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if epoch % config['save_interval'] == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'text_encoder': text_encoder.state_dict(),\n",
    "                'style_encoder': style_encoder.state_dict(),\n",
    "                'generator': generator.state_dict(),\n",
    "                'discriminator': discriminator.state_dict(),\n",
    "                'optimizer_G': optimizer_G.state_dict(),\n",
    "                'optimizer_D': optimizer_D.state_dict(),\n",
    "                'history': history,\n",
    "                'vocab': vocab,\n",
    "                'config': config\n",
    "            }\n",
    "            \n",
    "            ckpt_path = os.path.join(config['checkpoint_dir'], f'stage3_epoch_{epoch}.pth')\n",
    "            torch.save(checkpoint, ckpt_path)\n",
    "            print(f\" Checkpoint saved: {ckpt_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Training completed successfully!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Training interrupted by user. Saving checkpoint...\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'text_encoder': text_encoder.state_dict(),\n",
    "        'style_encoder': style_encoder.state_dict(),\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'optimizer_G': optimizer_G.state_dict(),\n",
    "        'optimizer_D': optimizer_D.state_dict(),\n",
    "        'history': history,\n",
    "        'vocab': vocab,\n",
    "        'config': config\n",
    "    }, os.path.join(config['checkpoint_dir'], f'stage3_interrupted_epoch_{epoch}.pth'))\n",
    "    print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error in Stage 3: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "\n",
    "def plot_improved_training_history(history):\n",
    "    \"\"\"Plot training curves for stage 3\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs = range(1, len(history['d_loss']) + 1)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    axes[0, 0].plot(epochs, history['d_loss'], 'b-', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Discriminator Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Generator losses\n",
    "    axes[0, 1].plot(epochs, history['g_adv_loss'], 'r-', linewidth=2, label='Adversarial')\n",
    "    axes[0, 1].plot(epochs, history['g_content_loss'], 'g-', linewidth=2, label='Content')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Generator Losses')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Discriminator accuracy\n",
    "    axes[1, 0].plot(epochs, history['d_real_acc'], 'b-', linewidth=2, label='Real Acc')\n",
    "    axes[1, 0].plot(epochs, history['d_fake_acc'], 'r-', linewidth=2, label='Fake Acc')\n",
    "    axes[1, 0].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy')\n",
    "    axes[1, 0].set_title('Discriminator Accuracy')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # D/G balance\n",
    "    avg_d_acc = [(r + f) / 2 for r, f in zip(history['d_real_acc'], history['d_fake_acc'])]\n",
    "    axes[1, 1].plot(epochs, avg_d_acc, 'purple', linewidth=2)\n",
    "    axes[1, 1].axhline(y=0.75, color='green', linestyle='--', alpha=0.5, label='Good Balance')\n",
    "    axes[1, 1].axhline(y=0.85, color='red', linestyle='--', alpha=0.5, label='D Too Strong')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Avg Accuracy')\n",
    "    axes[1, 1].set_title('D/G Balance (Lower = Better)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot if history is available\n",
    "if 'history' in dir() and len(history['d_loss']) > 0:\n",
    "    plot_improved_training_history(history)\n",
    "else:\n",
    "    print(\"No training history available yet. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52c5b1",
   "metadata": {},
   "source": [
    "## Inference and Testing\n",
    "\n",
    "Use trained models to generate handwriting samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16222826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_handwriting(text_encoder, style_encoder, generator, \n",
    "                        style_img, style_text, target_text, \n",
    "                        vocab, device):\n",
    "    \"\"\"\n",
    "    Generate handwriting for given target text in the style of style_img.\n",
    "    \n",
    "    Args:\n",
    "        text_encoder: trained text encoder\n",
    "        style_encoder: trained style encoder\n",
    "        generator: trained generator\n",
    "        style_img: PIL Image or tensor (1, 64, 256)\n",
    "        style_text: string\n",
    "        target_text: string to generate\n",
    "        vocab: character vocabulary\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        generated_img: numpy array (64, 256) in [0, 1]\n",
    "    \"\"\"\n",
    "    text_encoder.eval()\n",
    "    style_encoder.eval()\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare style image\n",
    "        if not isinstance(style_img, torch.Tensor):\n",
    "            style_img = T.ToTensor()(style_img) * 2 - 1  # [0,1] -> [-1,1]\n",
    "        \n",
    "        if style_img.dim() == 3:\n",
    "            style_img = style_img.unsqueeze(0)  # Add batch dim\n",
    "        \n",
    "        style_img = style_img.to(device)\n",
    "        \n",
    "        # Encode texts\n",
    "        style_text_indices = torch.tensor(\n",
    "            text_to_indices(style_text, vocab, max_len=60), \n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        target_text_indices = torch.tensor(\n",
    "            text_to_indices(target_text, vocab, max_len=20), \n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Encode\n",
    "        style_embed = style_encoder(style_img)\n",
    "        style_text_embed = text_encoder(style_text_indices)\n",
    "        target_text_embed = text_encoder(target_text_indices)\n",
    "        \n",
    "        # Generate\n",
    "        generated = generator(style_embed, style_text_embed, target_text_embed)\n",
    "        \n",
    "        # Convert to numpy [0, 1]\n",
    "        generated_np = (generated.cpu().squeeze().numpy() + 1) / 2\n",
    "        \n",
    "    return generated_np\n",
    "\n",
    "\n",
    "def visualize_custom_generation(text_encoder, style_encoder, generator,\n",
    "                                dataset, vocab, device, \n",
    "                                style_idx=0, target_texts=None):\n",
    "    \"\"\"\n",
    "    Generate multiple samples with same style but different target texts.\n",
    "    \"\"\"\n",
    "    if target_texts is None:\n",
    "        target_texts = [\"hello\", \"world\", \"test\", \"sample\"]\n",
    "    \n",
    "    # Get style sample\n",
    "    style_sample = dataset[style_idx]\n",
    "    style_img = style_sample['style_img']\n",
    "    style_text = style_sample['style_text']\n",
    "    \n",
    "    num_samples = len(target_texts)\n",
    "    fig, axes = plt.subplots(1, num_samples + 1, figsize=(4 * (num_samples + 1), 4))\n",
    "    \n",
    "    # Show style image\n",
    "    style_np = (style_img.squeeze().numpy() + 1) / 2\n",
    "    axes[0].imshow(style_np, cmap='gray')\n",
    "    axes[0].set_title(f\"Style Reference\\n'{style_text[:30]}'\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Generate for each target text\n",
    "    for i, target_text in enumerate(target_texts):\n",
    "        generated_np = generate_handwriting(\n",
    "            text_encoder, style_encoder, generator,\n",
    "            style_img, style_text, target_text,\n",
    "            vocab, device\n",
    "        )\n",
    "        \n",
    "        axes[i + 1].imshow(generated_np, cmap='gray')\n",
    "        axes[i + 1].set_title(f\"Generated\\n'{target_text}'\")\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\" Inference functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of inference (uncomment after training)\n",
    "# visualize_custom_generation(\n",
    "#     text_encoder, style_encoder, generator,\n",
    "#     improved_dataset, vocab, device,\n",
    "#     style_idx=10,\n",
    "#     target_texts=[\"hello\", \"world\", \"deep\", \"learning\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2c8e7",
   "metadata": {},
   "source": [
    "##  Summary of Improvements\n",
    "\n",
    "The new architecture addresses the issues with the naive model through several key improvements:\n",
    "\n",
    "### **Architecture Improvements:**\n",
    "\n",
    "1. **Multi-Word Style Context**\n",
    "   - Uses up to 3 consecutive words from the same line as style reference\n",
    "   - Provides richer style information from actual handwriting sequences\n",
    "   - Parses word IDs to intelligently select consecutive words\n",
    "\n",
    "2. **ScrabbleGAN-Style Generator**\n",
    "   - **AdaIN (Adaptive Instance Normalization)**: Injects style at every layer\n",
    "   - **Modulated Residual Blocks**: 6 blocks that adapt to style features\n",
    "   - **Better feature flow**: Style information modulates the entire generation process\n",
    "\n",
    "3. **Improved Style Encoder**\n",
    "   - Deeper architecture with residual blocks\n",
    "   - Writer classification capability for pretraining\n",
    "   - 512-dim style embeddings (vs 256 previously)\n",
    "\n",
    "4. **Patch-Based Discriminator**\n",
    "   - Outputs spatial grid of predictions (not single value)\n",
    "   - Better gradient flow for fine details\n",
    "   - Text-conditioned at spatial level\n",
    "\n",
    "### **Training Strategy Improvements:**\n",
    "\n",
    "**Stage 1: Style Encoder Pretraining (10 epochs)**\n",
    "   - Learn meaningful style representations via writer classification\n",
    "   - Achieves ~80%+ writer identification accuracy\n",
    "\n",
    "**Stage 2: Generator Pretraining (20 epochs)**\n",
    "   - Content-only training (L1 + L2 loss)\n",
    "   - Generator learns to produce readable text before adversarial training\n",
    "   - Stabilizes training significantly\n",
    "\n",
    "**Stage 3: Full GAN Training (100 epochs)**\n",
    "   - **Gradual adversarial loss**: Start at 0.1, increase to 1.0\n",
    "   - **Adaptive training**: Skip G updates if D accuracy > 85%\n",
    "   - **Feature matching**: Match discriminator features (not just fool it)\n",
    "   - **D/G balance monitoring**: Prevent mode collapse\n",
    "\n",
    "### **Loss Functions:**\n",
    "- Adversarial loss (BCE on patches)\n",
    "- Content loss (L1 for sharpness)\n",
    "- Feature matching loss (discriminator feature alignment)\n",
    "- Dynamic weighting based on training progress\n",
    "\n",
    "### **Key Differences from Naive Model:**\n",
    "| Aspect | Naive Model | Improved Model |\n",
    "|--------|-------------|----------------|\n",
    "| Style Context | Single random word | 3 consecutive words |\n",
    "| Generator | Simple UNet | AdaIN + Modulated ResBlocks |\n",
    "| Discriminator | Global single output | Patch-based spatial grid |\n",
    "| Training | Direct GAN training | 3-stage progressive |\n",
    "| Style Encoder | Basic CNN | PreTrained on writer ID |\n",
    "| Loss Balancing | Fixed weights | Adaptive + gradual |\n",
    "\n",
    "This should result in much more stable training and better quality handwriting generation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2f421",
   "metadata": {},
   "source": [
    "## Model Components\n",
    "\n",
    "Now let's build all the GAN components:\n",
    "1. Text Encoder (BiLSTM)\n",
    "2. Style Image Encoder (CNN)\n",
    "3. Generator (UNet-style)\n",
    "4. Discriminator (PatchGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ba2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes text (style_text or target_text) into embeddings using BiLSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, num_layers=2):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)  # bidirectional\n",
    "        \n",
    "    def forward(self, text_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_indices: (batch, max_len) - character indices\n",
    "        Returns:\n",
    "            text_embed: (batch, hidden_dim) - text embedding\n",
    "        \"\"\"\n",
    "        # text_indices: (batch, max_len)\n",
    "        embedded = self.embedding(text_indices)  # (batch, max_len, embedding_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)  # lstm_out: (batch, max_len, hidden_dim*2)\n",
    "        \n",
    "        # Use mean pooling over sequence\n",
    "        text_features = torch.mean(lstm_out, dim=1)  # (batch, hidden_dim*2)\n",
    "        \n",
    "        # Project to hidden_dim\n",
    "        text_embed = self.fc(text_features)  # (batch, hidden_dim)\n",
    "        \n",
    "        return text_embed\n",
    "\n",
    "# Test the text encoder\n",
    "text_encoder = TextEncoder(vocab_size=len(vocab), embedding_dim=128, hidden_dim=256)\n",
    "sample_indices = torch.tensor([encoded]).long()  # (1, max_len)\n",
    "text_embed = text_encoder(sample_indices)\n",
    "print(f\"Text embedding shape: {text_embed.shape}\")  # (1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf7396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleImageEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN-based encoder to extract style features from style_img\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, feature_dim=256):\n",
    "        super(StyleImageEncoder, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Input: (1, 64, 256)\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),  # (64, 32, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # (256, 8, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # (512, 4, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Global average pooling + FC\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 16, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, feature_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, style_img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256) - style image\n",
    "        Returns:\n",
    "            style_features: (batch, feature_dim) - style embedding\n",
    "        \"\"\"\n",
    "        features = self.conv_layers(style_img)  # (batch, 512, 4, 16)\n",
    "        features = features.view(features.size(0), -1)  # (batch, 512*4*16)\n",
    "        style_embed = self.fc(features)  # (batch, feature_dim)\n",
    "        return style_embed\n",
    "\n",
    "# Test the style encoder\n",
    "style_encoder = StyleImageEncoder(input_channels=1, feature_dim=256)\n",
    "sample_img = torch.randn(1, 1, 64, 256)  # (batch, channels, H, W)\n",
    "style_embed = style_encoder(sample_img)\n",
    "print(f\"Style embedding shape: {style_embed.shape}\")  # (1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator: Takes concatenated embeddings and generates target word in given style\n",
    "    Uses UNet-like architecture with skip connections\n",
    "    \"\"\"\n",
    "    def __init__(self, text_dim=256, style_dim=256, output_channels=1):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Total input embedding dimension\n",
    "        total_dim = text_dim * 2 + style_dim  # style_text + target_text + style_img\n",
    "        \n",
    "        # Project embeddings to spatial feature map\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_dim, 4 * 16 * 256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Decoder (upsampling) - UNet style\n",
    "        self.decoder = nn.Sequential(\n",
    "            # (256, 4, 16)\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),  # (256, 8, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # (64, 32, 128)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # (32, 64, 256)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, output_channels, kernel_size=3, stride=1, padding=1),  # (1, 64, 256)\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, style_img_embed, style_text_embed, target_text_embed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img_embed: (batch, style_dim)\n",
    "            style_text_embed: (batch, text_dim)\n",
    "            target_text_embed: (batch, text_dim)\n",
    "        Returns:\n",
    "            generated_img: (batch, 1, 64, 256) - generated image\n",
    "        \"\"\"\n",
    "        # Concatenate all embeddings\n",
    "        combined = torch.cat([style_img_embed, style_text_embed, target_text_embed], dim=1)\n",
    "        \n",
    "        # Project to spatial features\n",
    "        features = self.fc(combined)  # (batch, 4*16*256)\n",
    "        features = features.view(-1, 256, 4, 16)  # (batch, 256, 4, 16)\n",
    "        \n",
    "        # Decode to image\n",
    "        generated_img = self.decoder(features)  # (batch, 1, 64, 256)\n",
    "        \n",
    "        return generated_img\n",
    "\n",
    "# Test the generator\n",
    "generator = Generator(text_dim=256, style_dim=256, output_channels=1)\n",
    "style_img_embed = torch.randn(2, 256)\n",
    "style_text_embed = torch.randn(2, 256)\n",
    "target_text_embed = torch.randn(2, 256)\n",
    "generated = generator(style_img_embed, style_text_embed, target_text_embed)\n",
    "print(f\"Generated image shape: {generated.shape}\")  # (2, 1, 64, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional discriminator (PatchGAN style)\n",
    "    Judges if (style_img, generated_img/target_img) pair is real or fake\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=2, text_dim=256):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Convolutional layers (PatchGAN)\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Input: (2, 64, 256) - concatenated style_img and generated/target\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),  # (64, 32, 128)\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 64)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # (256, 8, 32)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # (512, 4, 16)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Text conditioning\n",
    "        self.text_fc = nn.Sequential(\n",
    "            nn.Linear(text_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Final classification\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 16 + 512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()  # Output probability\n",
    "        )\n",
    "        \n",
    "    def forward(self, style_img, target_or_gen_img, target_text_embed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256)\n",
    "            target_or_gen_img: (batch, 1, 64, 256) - real target or generated\n",
    "            target_text_embed: (batch, text_dim) - conditioning\n",
    "        Returns:\n",
    "            validity: (batch, 1) - probability of being real\n",
    "        \"\"\"\n",
    "        # Concatenate style and target/generated images\n",
    "        img_pair = torch.cat([style_img, target_or_gen_img], dim=1)  # (batch, 2, 64, 256)\n",
    "        \n",
    "        # Extract image features\n",
    "        img_features = self.conv_layers(img_pair)  # (batch, 512, 4, 16)\n",
    "        img_features = img_features.view(img_features.size(0), -1)  # (batch, 512*4*16)\n",
    "        \n",
    "        # Process text embedding\n",
    "        text_features = self.text_fc(target_text_embed)  # (batch, 512)\n",
    "        \n",
    "        # Combine image and text features\n",
    "        combined = torch.cat([img_features, text_features], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        validity = self.fc(combined)  # (batch, 1)\n",
    "        \n",
    "        return validity\n",
    "\n",
    "# Test the discriminator\n",
    "discriminator = Discriminator(input_channels=2, text_dim=256)\n",
    "style_img = torch.randn(2, 1, 64, 256)\n",
    "target_img = torch.randn(2, 1, 64, 256)\n",
    "target_text_embed = torch.randn(2, 256)\n",
    "validity = discriminator(style_img, target_img, target_text_embed)\n",
    "print(f\"Discriminator output shape: {validity.shape}\")  # (2, 1)\n",
    "print(f\"Validity scores: {validity.squeeze()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d999e5",
   "metadata": {},
   "source": [
    "## Update Dataset to Return Encoded Text\n",
    "\n",
    "Now we need to update our dataset to return encoded text indices along with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a39cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAMWordStyleDatasetWithText(Dataset):\n",
    "    \"\"\"Enhanced dataset that also returns encoded text\"\"\"\n",
    "    def __init__(self, df, words_root, vocab, target_size=(64, 256), max_text_len=20, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.words_root = words_root\n",
    "        self.vocab = vocab\n",
    "        self.target_size = target_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        word_id = row[\"id\"]\n",
    "        target_text = row[\"transcription\"]\n",
    "\n",
    "        # reconstruct file path\n",
    "        subdir = os.path.join(word_id[:3], f\"{word_id.split('-')[0]}-{word_id.split('-')[1]}\")\n",
    "        img_path = os.path.join(self.words_root, subdir, f\"{word_id}.png\")\n",
    "\n",
    "        # load target image\n",
    "        try:\n",
    "            target_img = Image.open(img_path).convert(\"L\")\n",
    "        except FileNotFoundError:\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "        # extract writer id\n",
    "        writer_id = word_id.split(\"-\")[0]\n",
    "\n",
    "        # get random style sample from same writer\n",
    "        same_writer_df = self.df[self.df[\"id\"].str.startswith(writer_id)]\n",
    "        same_writer_df = same_writer_df[same_writer_df[\"id\"] != word_id]\n",
    "        if same_writer_df.empty:\n",
    "            same_writer_df = self.df[self.df[\"id\"].str.startswith(writer_id)]\n",
    "        \n",
    "        style_row = same_writer_df.sample(1).iloc[0]\n",
    "        style_word_id = style_row[\"id\"]\n",
    "        style_text = style_row[\"transcription\"]\n",
    "\n",
    "        style_subdir = os.path.join(style_word_id[:3], f\"{style_word_id.split('-')[0]}-{style_word_id.split('-')[1]}\")\n",
    "        style_path = os.path.join(self.words_root, style_subdir, f\"{style_word_id}.png\")\n",
    "\n",
    "        try:\n",
    "            style_img = Image.open(style_path).convert(\"L\")\n",
    "        except FileNotFoundError:\n",
    "            style_img = target_img\n",
    "\n",
    "        # pad images\n",
    "        style_img = self._pad_image(style_img)\n",
    "        target_img = self._pad_image(target_img)\n",
    "        \n",
    "        # convert to tensor (normalize to [-1, 1] for GAN)\n",
    "        style_img = T.ToTensor()(style_img) * 2 - 1  # [0,1] -> [-1,1]\n",
    "        target_img = T.ToTensor()(target_img) * 2 - 1\n",
    "        \n",
    "        # apply additional transforms if any\n",
    "        if self.transform:\n",
    "            style_img = self.transform(style_img)\n",
    "            target_img = self.transform(target_img)\n",
    "        \n",
    "        # encode text to indices\n",
    "        style_text_indices = text_to_indices(style_text, self.vocab, self.max_text_len)\n",
    "        target_text_indices = text_to_indices(target_text, self.vocab, self.max_text_len)\n",
    "        \n",
    "        return {\n",
    "            \"style_img\": style_img,\n",
    "            \"style_text\": style_text,\n",
    "            \"style_text_indices\": torch.tensor(style_text_indices, dtype=torch.long),\n",
    "            \"target_img\": target_img,\n",
    "            \"target_text\": target_text,\n",
    "            \"target_text_indices\": torch.tensor(target_text_indices, dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def _pad_image(self, img):\n",
    "        \"\"\"Pad image to target size maintaining aspect ratio with white padding\"\"\"\n",
    "        target_h, target_w = self.target_size\n",
    "        w, h = img.size\n",
    "        \n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        \n",
    "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        \n",
    "        padded = Image.new(\"L\", (target_w, target_h), 255)\n",
    "        \n",
    "        paste_x = (target_w - new_w) // 2\n",
    "        paste_y = (target_h - new_h) // 2\n",
    "        padded.paste(img, (paste_x, paste_y))\n",
    "        \n",
    "        return padded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Test the enhanced dataset\n",
    "dataset_with_text = IAMWordStyleDatasetWithText(df, \"iam_words/words\", vocab)\n",
    "sample = dataset_with_text[0]\n",
    "\n",
    "print(f\"Style image shape: {sample['style_img'].shape}\")\n",
    "print(f\"Target image shape: {sample['target_img'].shape}\")\n",
    "print(f\"Style text: '{sample['style_text']}'\")\n",
    "print(f\"Style text indices shape: {sample['style_text_indices'].shape}\")\n",
    "print(f\"Target text: '{sample['target_text']}'\")\n",
    "print(f\"Target text indices shape: {sample['target_text_indices'].shape}\")\n",
    "print(f\"Image value range: [{sample['target_img'].min():.2f}, {sample['target_img'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5a7a6",
   "metadata": {},
   "source": [
    "## Create DataLoader and Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00baffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = IAMWordStyleDatasetWithText(df, \"iam_words/words\", vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# Initialize models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "text_encoder = TextEncoder(vocab_size=len(vocab), embedding_dim=128, hidden_dim=256).to(device)\n",
    "style_encoder = StyleImageEncoder(input_channels=1, feature_dim=256).to(device)\n",
    "generator = Generator(text_dim=256, style_dim=256, output_channels=1).to(device)\n",
    "discriminator = Discriminator(input_channels=2, text_dim=256).to(device)\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"Text Encoder: {count_parameters(text_encoder):,}\")\n",
    "print(f\"Style Encoder: {count_parameters(style_encoder):,}\")\n",
    "print(f\"Generator: {count_parameters(generator):,}\")\n",
    "print(f\"Discriminator: {count_parameters(discriminator):,}\")\n",
    "print(f\"Total: {count_parameters(text_encoder) + count_parameters(style_encoder) + count_parameters(generator) + count_parameters(discriminator):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f195a85",
   "metadata": {},
   "source": [
    "## Define Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27617810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = nn.BCELoss()\n",
    "content_loss = nn.L1Loss()\n",
    "\n",
    "# Optimizers\n",
    "lr_g = 0.0002\n",
    "lr_d = 0.0001\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# Generator optimizer (includes text encoder, style encoder, and generator)\n",
    "optimizer_G = optim.Adam(\n",
    "    list(text_encoder.parameters()) + \n",
    "    list(style_encoder.parameters()) + \n",
    "    list(generator.parameters()),\n",
    "    lr=lr_g, \n",
    "    betas=(beta1, beta2)\n",
    ")\n",
    "\n",
    "# Discriminator optimizer\n",
    "optimizer_D = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=lr_d, \n",
    "    betas=(beta1, beta2)\n",
    ")\n",
    "\n",
    "print(\"Optimizers initialized!\")\n",
    "print(f\"Generator LR: {lr_g}, Discriminator LR: {lr_d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a68c31",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now let's implement the complete training loop with:\n",
    "- Adversarial loss (real/fake discrimination)\n",
    "- Content loss (L1 between generated and target)\n",
    "- Logging and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def train_epoch(text_encoder, style_encoder, generator, discriminator, \n",
    "                train_loader, optimizer_G, optimizer_D, device, epoch, \n",
    "                lambda_content=100):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    \n",
    "    text_encoder.train()\n",
    "    style_encoder.train()\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_loss = 0\n",
    "    epoch_content_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        batch_size = batch['style_img'].size(0)\n",
    "        \n",
    "        # Move to device\n",
    "        style_img = batch['style_img'].to(device)\n",
    "        target_img = batch['target_img'].to(device)\n",
    "        style_text_indices = batch['style_text_indices'].to(device)\n",
    "        target_text_indices = batch['target_text_indices'].to(device)\n",
    "        \n",
    "        # Real and fake labels\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # =================== Train Discriminator ===================\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Encode text and style\n",
    "        with torch.no_grad():\n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            style_img_embed = style_encoder(style_img)\n",
    "        \n",
    "        # Generate fake images\n",
    "        with torch.no_grad():\n",
    "            fake_img = generator(style_img_embed, style_text_embed, target_text_embed)\n",
    "        \n",
    "        # Real loss\n",
    "        real_validity = discriminator(style_img, target_img, target_text_embed)\n",
    "        d_real_loss = adversarial_loss(real_validity, real_labels)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_validity = discriminator(style_img, fake_img.detach(), target_text_embed)\n",
    "        d_fake_loss = adversarial_loss(fake_validity, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # =================== Train Generator ===================\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Encode (without no_grad this time)\n",
    "        style_text_embed = text_encoder(style_text_indices)\n",
    "        target_text_embed = text_encoder(target_text_indices)\n",
    "        style_img_embed = style_encoder(style_img)\n",
    "        \n",
    "        # Generate images\n",
    "        fake_img = generator(style_img_embed, style_text_embed, target_text_embed)\n",
    "        \n",
    "        # Adversarial loss (fool discriminator)\n",
    "        fake_validity = discriminator(style_img, fake_img, target_text_embed)\n",
    "        g_adv_loss = adversarial_loss(fake_validity, real_labels)\n",
    "        \n",
    "        # Content loss (L1)\n",
    "        g_content_loss = content_loss(fake_img, target_img)\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_loss = g_adv_loss + lambda_content * g_content_loss\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_adv_loss.item()\n",
    "        epoch_content_loss += g_content_loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'D_loss': f'{d_loss.item():.4f}',\n",
    "            'G_loss': f'{g_adv_loss.item():.4f}',\n",
    "            'Content': f'{g_content_loss.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    # Average losses\n",
    "    n_batches = len(train_loader)\n",
    "    return {\n",
    "        'd_loss': epoch_d_loss / n_batches,\n",
    "        'g_loss': epoch_g_loss / n_batches,\n",
    "        'content_loss': epoch_content_loss / n_batches\n",
    "    }\n",
    "\n",
    "print(\"Training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abe592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(text_encoder, style_encoder, generator, dataset, device, num_samples=4):\n",
    "    \"\"\"Visualize generated samples\"\"\"\n",
    "    text_encoder.eval()\n",
    "    style_encoder.eval()\n",
    "    generator.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, num_samples * 3))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i]\n",
    "            \n",
    "            # Prepare inputs\n",
    "            style_img = sample['style_img'].unsqueeze(0).to(device)\n",
    "            style_text_indices = sample['style_text_indices'].unsqueeze(0).to(device)\n",
    "            target_text_indices = sample['target_text_indices'].unsqueeze(0).to(device)\n",
    "            target_img = sample['target_img']\n",
    "            \n",
    "            # Generate\n",
    "            style_text_embed = text_encoder(style_text_indices)\n",
    "            target_text_embed = text_encoder(target_text_indices)\n",
    "            style_img_embed = style_encoder(style_img)\n",
    "            fake_img = generator(style_img_embed, style_text_embed, target_text_embed)\n",
    "            \n",
    "            # Convert to numpy for display ([-1, 1] -> [0, 1])\n",
    "            style_np = (style_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            target_np = (target_img.squeeze().numpy() + 1) / 2\n",
    "            fake_np = (fake_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(style_np, cmap='gray')\n",
    "            axes[i, 0].set_title(f\"Style: '{sample['style_text']}'\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(fake_np, cmap='gray')\n",
    "            axes[i, 1].set_title(f\"Generated: '{sample['target_text']}'\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(target_np, cmap='gray')\n",
    "            axes[i, 2].set_title(f\"Ground Truth: '{sample['target_text']}'\")\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Visualization function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa23d4",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "Now everything is ready! Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 50\n",
    "lambda_content = 100  # weight for content loss\n",
    "save_interval = 5  # save model every N epochs\n",
    "\n",
    "# Create directory for saving models\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'd_loss': [],\n",
    "    'g_loss': [],\n",
    "    'content_loss': []\n",
    "}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Batch size: {train_loader.batch_size}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")\n",
    "print(f\"Lambda content: {lambda_content}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f0c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    try:\n",
    "        # Train one epoch safely\n",
    "        losses = train_epoch(\n",
    "            text_encoder, style_encoder, generator, discriminator,\n",
    "            train_loader, optimizer_G, optimizer_D, device, epoch,\n",
    "            lambda_content=lambda_content\n",
    "        )\n",
    "\n",
    "        # Store history\n",
    "        history['d_loss'].append(losses.get('d_loss', 0.0))\n",
    "        history['g_loss'].append(losses.get('g_loss', 0.0))\n",
    "        history['content_loss'].append(losses.get('content_loss', 0.0))\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs} Summary:\")\n",
    "        print(f\"  D Loss: {losses['d_loss']:.4f}\")\n",
    "        print(f\"  G Loss: {losses['g_loss']:.4f}\")\n",
    "        print(f\"  Content Loss: {losses['content_loss']:.4f}\")\n",
    "\n",
    "        # Visualize occasionally\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"\\nVisualizing results at epoch {epoch}...\")\n",
    "            try:\n",
    "                visualize_results(\n",
    "                    text_encoder, style_encoder, generator,\n",
    "                    train_dataset, device, num_samples=4\n",
    "                )\n",
    "            except UnidentifiedImageError as e:\n",
    "                print(f\"[WARN] Visualization skipped due to bad image: {e}\")\n",
    "\n",
    "        # Save checkpoints regularly\n",
    "        if epoch % save_interval == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'text_encoder': text_encoder.state_dict(),\n",
    "                'style_encoder': style_encoder.state_dict(),\n",
    "                'generator': generator.state_dict(),\n",
    "                'discriminator': discriminator.state_dict(),\n",
    "                'optimizer_G': optimizer_G.state_dict(),\n",
    "                'optimizer_D': optimizer_D.state_dict(),\n",
    "                'history': history,\n",
    "                'vocab': vocab\n",
    "            }\n",
    "\n",
    "            os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "            ckpt_path = f'checkpoints/checkpoint_epoch_{epoch}.pth'\n",
    "            torch.save(checkpoint, ckpt_path)\n",
    "            print(f\" Checkpoint saved: {ckpt_path}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n Training interrupted by user. Saving checkpoint...\")\n",
    "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'text_encoder': text_encoder.state_dict(),\n",
    "            'style_encoder': style_encoder.state_dict(),\n",
    "            'generator': generator.state_dict(),\n",
    "            'discriminator': discriminator.state_dict(),\n",
    "            'optimizer_G': optimizer_G.state_dict(),\n",
    "            'optimizer_D': optimizer_D.state_dict(),\n",
    "            'history': history,\n",
    "            'vocab': vocab\n",
    "        }, f'checkpoints/interrupt_checkpoint_epoch_{epoch}.pth')\n",
    "        print(f\"Checkpoint saved. You can resume from epoch {epoch}.\")\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Unexpected error in epoch {epoch}: {e}\")\n",
    "        # continue training from next epoch safely\n",
    "\n",
    "print(\"\\n Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d5621",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training losses\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    epochs = range(1, len(history['d_loss']) + 1)\n",
    "    \n",
    "    axes[0].plot(epochs, history['d_loss'], 'b-', label='Discriminator Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Discriminator Loss')\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].plot(epochs, history['g_loss'], 'r-', label='Generator Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_title('Generator Adversarial Loss')\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    axes[2].plot(epochs, history['content_loss'], 'g-', label='Content Loss (L1)')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].set_title('Content Loss')\n",
    "    axes[2].grid(True)\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot after training completes\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8893df",
   "metadata": {},
   "source": [
    "##  Alternative Architecture: Style Transfer Approach\n",
    "\n",
    "**Key Insight**: Instead of generating from embeddings, we'll do image-to-image translation:\n",
    "- **Input 1**: Style reference (real handwriting of 1-3 words)\n",
    "- **Input 2**: Plain font rendering of target text (structural guide)\n",
    "- **Output**: Stylized version of the plain text\n",
    "\n",
    "This is much more stable because:\n",
    "1. Generator has structural guidance (doesn't need to learn letter shapes from scratch)\n",
    "2. Task is style transfer, not generation\n",
    "3. Similar to pix2pix - proven architecture\n",
    "4. Plain text acts as a \"sketch\" that needs to be \"painted\" in the target style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711aa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Text rendering utilities\n",
    "\n",
    "def render_text_to_image(text, size=(64, 256), font_size=32):\n",
    "    \"\"\"\n",
    "    Render text in a plain font to create a structural guide image.\n",
    "    This will be the input to our generator.\n",
    "    \"\"\"\n",
    "    img = Image.new('L', size, color=255)  # White background\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Try to use a simple font, fallback to default\n",
    "    try:\n",
    "        # Try common system fonts\n",
    "        font_paths = [\n",
    "            \"C:/Windows/Fonts/arial.ttf\",\n",
    "            \"C:/Windows/Fonts/calibri.ttf\",\n",
    "            \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
    "            \"/System/Library/Fonts/Helvetica.ttc\"\n",
    "        ]\n",
    "        \n",
    "        font = None\n",
    "        for path in font_paths:\n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    font = ImageFont.truetype(path, font_size)\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        if font is None:\n",
    "            font = ImageFont.load_default()\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Get text bounding box\n",
    "    try:\n",
    "        bbox = draw.textbbox((0, 0), text, font=font)\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "    except:\n",
    "        # Fallback for older PIL versions\n",
    "        text_width, text_height = draw.textsize(text, font=font)\n",
    "    \n",
    "    # Center the text\n",
    "    x = (size[1] - text_width) // 2\n",
    "    y = (size[0] - text_height) // 2\n",
    "    \n",
    "    # Draw text in black\n",
    "    draw.text((x, y), text, fill=0, font=font)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Test text rendering\n",
    "test_text = \"hello\"\n",
    "test_img = render_text_to_image(test_text)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title(f\"Rendered: '{test_text}'\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\" Text rendering function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for style transfer approach.\n",
    "    Returns:\n",
    "    - style_img: Real handwriting of 1-3 consecutive words (for style reference)\n",
    "    - plain_text_img: Plain font rendering of target text (structural guide)\n",
    "    - target_img: Real handwriting of target text (ground truth)\n",
    "    \"\"\"\n",
    "    def __init__(self, df, words_root, target_size=(64, 256), max_style_words=3, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.words_root = words_root\n",
    "        self.target_size = target_size\n",
    "        self.max_style_words = max_style_words\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Create index for fast lookup\n",
    "        self.line_index = {}\n",
    "        for idx, row in df.iterrows():\n",
    "            word_id = row[\"id\"]\n",
    "            parts = word_id.split(\"-\")\n",
    "            if len(parts) >= 4:\n",
    "                writer = parts[0]\n",
    "                form = parts[1]\n",
    "                line = parts[2]\n",
    "                word_num = parts[3]\n",
    "                key = (writer, form, line)\n",
    "                if key not in self.line_index:\n",
    "                    self.line_index[key] = []\n",
    "                self.line_index[key].append((idx, int(word_num)))\n",
    "        \n",
    "        for key in self.line_index:\n",
    "            self.line_index[key].sort(key=lambda x: x[1])\n",
    "    \n",
    "    def _parse_word_id(self, word_id):\n",
    "        parts = word_id.split(\"-\")\n",
    "        if len(parts) >= 4:\n",
    "            return parts[0], parts[1], parts[2], int(parts[3])\n",
    "        return None, None, None, None\n",
    "    \n",
    "    def _get_consecutive_style_words(self, writer, form, line, exclude_word_num=None):\n",
    "        \"\"\"Get up to max_style_words consecutive words from same line\"\"\"\n",
    "        key = (writer, form, line)\n",
    "        if key not in self.line_index:\n",
    "            return []\n",
    "        \n",
    "        words_in_line = self.line_index[key]\n",
    "        \n",
    "        if exclude_word_num is not None:\n",
    "            words_in_line = [(idx, wn) for idx, wn in words_in_line if wn != exclude_word_num]\n",
    "        \n",
    "        if not words_in_line:\n",
    "            return []\n",
    "        \n",
    "        if len(words_in_line) <= self.max_style_words:\n",
    "            selected = words_in_line\n",
    "        else:\n",
    "            start_idx = random.randint(0, len(words_in_line) - self.max_style_words)\n",
    "            selected = words_in_line[start_idx:start_idx + self.max_style_words]\n",
    "        \n",
    "        return [idx for idx, _ in selected]\n",
    "    \n",
    "    def _load_image(self, word_id):\n",
    "        parts = word_id.split(\"-\")\n",
    "        if len(parts) < 2:\n",
    "            return None\n",
    "        \n",
    "        writer = parts[0]\n",
    "        form = f\"{parts[0]}-{parts[1]}\"\n",
    "        img_path = os.path.join(self.words_root, writer, form, f\"{word_id}.png\")\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            return img\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _pad_image(self, img):\n",
    "        target_h, target_w = self.target_size\n",
    "        w, h = img.size\n",
    "        \n",
    "        scale = min(target_w / w, target_h / h)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        \n",
    "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        padded = Image.new(\"L\", (target_w, target_h), 255)\n",
    "        \n",
    "        paste_x = (target_w - new_w) // 2\n",
    "        paste_y = (target_h - new_h) // 2\n",
    "        padded.paste(img, (paste_x, paste_y))\n",
    "        \n",
    "        return padded\n",
    "    \n",
    "    def _concatenate_images_horizontal(self, images):\n",
    "        if not images:\n",
    "            return Image.new(\"L\", self.target_size, 255)\n",
    "        \n",
    "        total_width = sum(img.size[0] for img in images)\n",
    "        max_height = max(img.size[1] for img in images)\n",
    "        \n",
    "        concat = Image.new(\"L\", (total_width, max_height), 255)\n",
    "        x_offset = 0\n",
    "        for img in images:\n",
    "            concat.paste(img, (x_offset, 0))\n",
    "            x_offset += img.size[0]\n",
    "        \n",
    "        return concat\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        word_id = row[\"id\"]\n",
    "        target_text = row[\"transcription\"]\n",
    "        \n",
    "        writer, form, line, word_num = self._parse_word_id(word_id)\n",
    "        \n",
    "        # Load TARGET image (ground truth)\n",
    "        target_img = self._load_image(word_id)\n",
    "        if target_img is None:\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "        \n",
    "        # Get STYLE images (consecutive words from same writer/line)\n",
    "        style_indices = []\n",
    "        if writer and form and line:\n",
    "            style_indices = self._get_consecutive_style_words(writer, form, line, exclude_word_num=word_num)\n",
    "        \n",
    "        # Fallback to random word from same writer\n",
    "        if not style_indices:\n",
    "            same_writer_df = self.df[self.df[\"id\"].str.startswith(writer) if writer else False]\n",
    "            same_writer_df = same_writer_df[same_writer_df[\"id\"] != word_id]\n",
    "            if not same_writer_df.empty:\n",
    "                style_row = same_writer_df.sample(1).iloc[0]\n",
    "                style_idx = same_writer_df.index[same_writer_df[\"id\"] == style_row[\"id\"]].tolist()[0]\n",
    "                style_indices = [style_idx]\n",
    "            else:\n",
    "                # Last resort: use different word from dataset\n",
    "                style_indices = [(idx + 1) % len(self.df)]\n",
    "        \n",
    "        # Load and concatenate style images\n",
    "        style_images = []\n",
    "        for s_idx in style_indices:\n",
    "            s_row = self.df.iloc[s_idx]\n",
    "            s_img = self._load_image(s_row[\"id\"])\n",
    "            if s_img is not None:\n",
    "                style_images.append(s_img)\n",
    "        \n",
    "        if len(style_images) > 1:\n",
    "            style_img_concat = self._concatenate_images_horizontal(style_images)\n",
    "        elif len(style_images) == 1:\n",
    "            style_img_concat = style_images[0]\n",
    "        else:\n",
    "            style_img_concat = target_img\n",
    "        \n",
    "        # Generate PLAIN TEXT rendering of target text\n",
    "        plain_text_img = render_text_to_image(target_text, size=self.target_size)\n",
    "        \n",
    "        # Pad all images\n",
    "        style_img_concat = self._pad_image(style_img_concat)\n",
    "        target_img = self._pad_image(target_img)\n",
    "        # plain_text_img already at target size\n",
    "        \n",
    "        # Convert to tensor [-1, 1]\n",
    "        style_img_tensor = T.ToTensor()(style_img_concat) * 2 - 1\n",
    "        plain_text_tensor = T.ToTensor()(plain_text_img) * 2 - 1\n",
    "        target_img_tensor = T.ToTensor()(target_img) * 2 - 1\n",
    "        \n",
    "        if self.transform:\n",
    "            style_img_tensor = self.transform(style_img_tensor)\n",
    "            plain_text_tensor = self.transform(plain_text_tensor)\n",
    "            target_img_tensor = self.transform(target_img_tensor)\n",
    "        \n",
    "        return {\n",
    "            \"style_img\": style_img_tensor,          # Real handwriting (for style)\n",
    "            \"plain_text_img\": plain_text_tensor,    # Plain font (structural guide)\n",
    "            \"target_img\": target_img_tensor,        # Real handwriting (ground truth)\n",
    "            \"target_text\": target_text,\n",
    "            \"writer_id\": writer if writer else \"unknown\"\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "# Test the new dataset\n",
    "print(\"Creating style transfer dataset...\")\n",
    "style_transfer_dataset = StyleTransferDataset(df, \"iam_words/words\", max_style_words=3)\n",
    "\n",
    "sample = style_transfer_dataset[5]\n",
    "print(f\"Dataset sample:\")\n",
    "print(f\"  Style img shape: {sample['style_img'].shape}\")\n",
    "print(f\"  Plain text img shape: {sample['plain_text_img'].shape}\")\n",
    "print(f\"  Target img shape: {sample['target_img'].shape}\")\n",
    "print(f\"  Target text: '{sample['target_text']}'\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow((sample['style_img'].squeeze().numpy() + 1) / 2, cmap='gray')\n",
    "axes[0].set_title('Style Reference\\n(Real Handwriting)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow((sample['plain_text_img'].squeeze().numpy() + 1) / 2, cmap='gray')\n",
    "axes[1].set_title(f'Plain Text Input\\n\"{sample[\"target_text\"]}\"')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow((sample['target_img'].squeeze().numpy() + 1) / 2, cmap='gray')\n",
    "axes[2].set_title('Target Output\\n(Ground Truth)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\" Style transfer dataset ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlock(nn.Module):\n",
    "    \"\"\"UNet encoder/decoder block with skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, normalize=True, dropout=0.0):\n",
    "        super(UNetBlock, self).__init__()\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    \"\"\"UNet decoder block with skip connections\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.0):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        layers = [\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        ]\n",
    "        if dropout:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, skip_input):\n",
    "        x = self.model(x)\n",
    "        x = torch.cat([x, skip_input], 1)  # Concatenate skip connection\n",
    "        return x\n",
    "\n",
    "\n",
    "class StyleTransferGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet-based generator for style transfer.\n",
    "    Input: Concatenation of [style_img, plain_text_img]\n",
    "    Output: Stylized version of plain_text_img\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(StyleTransferGenerator, self).__init__()\n",
    "        \n",
    "        # ENCODER (Downsampling with skip connections)\n",
    "        self.down1 = UNetBlock(in_channels, 64, normalize=False)  # (64, 32, 128)\n",
    "        self.down2 = UNetBlock(64, 128)                           # (128, 16, 64)\n",
    "        self.down3 = UNetBlock(128, 256)                          # (256, 8, 32)\n",
    "        self.down4 = UNetBlock(256, 512, dropout=0.5)             # (512, 4, 16)\n",
    "        self.down5 = UNetBlock(512, 512, dropout=0.5)             # (512, 2, 8)\n",
    "        self.down6 = UNetBlock(512, 512, dropout=0.5)             # (512, 1, 4)\n",
    "        \n",
    "        # BOTTLENECK\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),  # (512, 1, 2) - very compressed\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # DECODER (Upsampling with skip connections)\n",
    "        self.up1 = UNetUpBlock(512, 512, dropout=0.5)      # + down6 -> (1024, 1, 4)\n",
    "        self.up2 = UNetUpBlock(1024, 512, dropout=0.5)     # + down5 -> (1024, 2, 8)\n",
    "        self.up3 = UNetUpBlock(1024, 512, dropout=0.5)     # + down4 -> (1024, 4, 16)\n",
    "        self.up4 = UNetUpBlock(1024, 256)                  # + down3 -> (512, 8, 32)\n",
    "        self.up5 = UNetUpBlock(512, 128)                   # + down2 -> (256, 16, 64)\n",
    "        self.up6 = UNetUpBlock(256, 64)                    # + down1 -> (128, 32, 128)\n",
    "        \n",
    "        # Final upsampling\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, out_channels, 4, 2, 1),  # (1, 64, 256)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, style_img, plain_text_img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256) - style reference\n",
    "            plain_text_img: (batch, 1, 64, 256) - plain text to stylize\n",
    "        Returns:\n",
    "            stylized_img: (batch, 1, 64, 256) - stylized output\n",
    "        \"\"\"\n",
    "        # Concatenate inputs\n",
    "        x = torch.cat([style_img, plain_text_img], dim=1)  # (batch, 2, 64, 256)\n",
    "        \n",
    "        # Encoder with skip connections\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "        d5 = self.down5(d4)\n",
    "        d6 = self.down6(d5)\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(d6)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        u1 = self.up1(bottleneck, d6)\n",
    "        u2 = self.up2(u1, d5)\n",
    "        u3 = self.up3(u2, d4)\n",
    "        u4 = self.up4(u3, d3)\n",
    "        u5 = self.up5(u4, d2)\n",
    "        u6 = self.up6(u5, d1)\n",
    "        \n",
    "        # Final output\n",
    "        output = self.final(u6)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# Test the generator\n",
    "print(\"Testing StyleTransferGenerator...\")\n",
    "test_gen = StyleTransferGenerator(in_channels=2, out_channels=1)\n",
    "test_style = torch.randn(2, 1, 64, 256)\n",
    "test_plain = torch.randn(2, 1, 64, 256)\n",
    "test_output = test_gen(test_style, test_plain)\n",
    "\n",
    "print(f\"Input shapes:\")\n",
    "print(f\"  Style: {test_style.shape}\")\n",
    "print(f\"  Plain text: {test_plain.shape}\")\n",
    "print(f\"Output shape: {test_output.shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in test_gen.parameters()):,}\")\n",
    "print(\" StyleTransferGenerator defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be777fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchGAN discriminator for style transfer.\n",
    "    Judges if (style_img, plain_text, generated/target) triplet is real or fake.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3):  # style + plain + generated/target\n",
    "        super(StyleTransferDiscriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, normalize=True):\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Input: (3, 64, 256) - concatenated [style, plain, generated/target]\n",
    "            *discriminator_block(in_channels, 64, normalize=False),  # (64, 32, 128)\n",
    "            *discriminator_block(64, 128),                           # (128, 16, 64)\n",
    "            *discriminator_block(128, 256),                          # (256, 8, 32)\n",
    "            *discriminator_block(256, 512),                          # (512, 4, 16)\n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),                             # Padding for output\n",
    "            nn.Conv2d(512, 1, 4, padding=1),                        # (1, 4, 16) - patch predictions\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, style_img, plain_text_img, generated_or_target_img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            style_img: (batch, 1, 64, 256)\n",
    "            plain_text_img: (batch, 1, 64, 256)\n",
    "            generated_or_target_img: (batch, 1, 64, 256)\n",
    "        Returns:\n",
    "            validity: (batch, 1, H, W) - patch-wise real/fake predictions\n",
    "        \"\"\"\n",
    "        # Concatenate all inputs\n",
    "        img_input = torch.cat([style_img, plain_text_img, generated_or_target_img], 1)\n",
    "        return self.model(img_input)\n",
    "\n",
    "\n",
    "# Test discriminator\n",
    "print(\"Testing StyleTransferDiscriminator...\")\n",
    "test_disc = StyleTransferDiscriminator(in_channels=3)\n",
    "test_style = torch.randn(2, 1, 64, 256)\n",
    "test_plain = torch.randn(2, 1, 64, 256)\n",
    "test_target = torch.randn(2, 1, 64, 256)\n",
    "test_validity = test_disc(test_style, test_plain, test_target)\n",
    "\n",
    "print(f\"Input shapes:\")\n",
    "print(f\"  Style: {test_style.shape}\")\n",
    "print(f\"  Plain: {test_plain.shape}\")\n",
    "print(f\"  Target: {test_target.shape}\")\n",
    "print(f\"Output shape: {test_validity.shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in test_disc.parameters()):,}\")\n",
    "print(\" StyleTransferDiscriminator defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b2c3d",
   "metadata": {},
   "source": [
    "## Training for Style Transfer Approach\n",
    "\n",
    "This is much simpler - we can train directly with GAN loss + L1 loss since the generator has structural guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_style_transfer_epoch(generator, discriminator, train_loader, \n",
    "                               optimizer_G, optimizer_D, device, epoch,\n",
    "                               lambda_l1=100):\n",
    "    \"\"\"\n",
    "    Train style transfer GAN for one epoch.\n",
    "    Much simpler than before - no pretraining needed!\n",
    "    \"\"\"\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_gan_loss = 0\n",
    "    epoch_g_l1_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        batch_size = batch['style_img'].size(0)\n",
    "        \n",
    "        style_img = batch['style_img'].to(device)\n",
    "        plain_text_img = batch['plain_text_img'].to(device)\n",
    "        target_img = batch['target_img'].to(device)\n",
    "        \n",
    "        # Real and fake labels for patches\n",
    "        real_labels = torch.ones(batch_size, 1, 4, 16).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, 4, 16).to(device)\n",
    "        \n",
    "        # =================== Train Discriminator ===================\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Generate fake images\n",
    "        with torch.no_grad():\n",
    "            fake_img = generator(style_img, plain_text_img)\n",
    "        \n",
    "        # Real loss\n",
    "        real_validity = discriminator(style_img, plain_text_img, target_img)\n",
    "        d_real_loss = F.binary_cross_entropy(real_validity, real_labels)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_validity = discriminator(style_img, plain_text_img, fake_img.detach())\n",
    "        d_fake_loss = F.binary_cross_entropy(fake_validity, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # =================== Train Generator ===================\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Generate images\n",
    "        fake_img = generator(style_img, plain_text_img)\n",
    "        \n",
    "        # GAN loss (fool discriminator)\n",
    "        fake_validity = discriminator(style_img, plain_text_img, fake_img)\n",
    "        g_gan_loss = F.binary_cross_entropy(fake_validity, real_labels)\n",
    "        \n",
    "        # L1 loss (pixel-wise similarity)\n",
    "        g_l1_loss = F.l1_loss(fake_img, target_img)\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_loss = g_gan_loss + lambda_l1 * g_l1_loss\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_gan_loss += g_gan_loss.item()\n",
    "        epoch_g_l1_loss += g_l1_loss.item()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'D': f'{d_loss.item():.3f}',\n",
    "            'G_gan': f'{g_gan_loss.item():.3f}',\n",
    "            'G_L1': f'{g_l1_loss.item():.3f}'\n",
    "        })\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    return {\n",
    "        'd_loss': epoch_d_loss / n_batches,\n",
    "        'g_gan_loss': epoch_g_gan_loss / n_batches,\n",
    "        'g_l1_loss': epoch_g_l1_loss / n_batches\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_style_transfer_results(generator, dataset, device, num_samples=4):\n",
    "    \"\"\"Visualize style transfer results\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples * 3))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i * len(dataset) // num_samples]\n",
    "            \n",
    "            style_img = sample['style_img'].unsqueeze(0).to(device)\n",
    "            plain_text_img = sample['plain_text_img'].unsqueeze(0).to(device)\n",
    "            target_img = sample['target_img']\n",
    "            \n",
    "            # Generate\n",
    "            fake_img = generator(style_img, plain_text_img)\n",
    "            \n",
    "            # Convert to numpy [0, 1]\n",
    "            style_np = (style_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            plain_np = (plain_text_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            fake_np = (fake_img.cpu().squeeze().numpy() + 1) / 2\n",
    "            target_np = (target_img.squeeze().numpy() + 1) / 2\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(style_np, cmap='gray')\n",
    "            axes[i, 0].set_title('Style Reference')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(plain_np, cmap='gray')\n",
    "            axes[i, 1].set_title(f'Plain Input\\n\"{sample[\"target_text\"]}\"')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(fake_np, cmap='gray')\n",
    "            axes[i, 2].set_title('Generated (Stylized)')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            axes[i, 3].imshow(target_np, cmap='gray')\n",
    "            axes[i, 3].set_title('Ground Truth')\n",
    "            axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    generator.train()\n",
    "\n",
    "\n",
    "print(\" Style transfer training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d321420",
   "metadata": {},
   "source": [
    "## Initialize and Train Style Transfer Model\n",
    "\n",
    "This is the recommended approach - much more stable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize style transfer models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\\n\")\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating style transfer dataset...\")\n",
    "st_dataset = StyleTransferDataset(df, \"iam_words/words\", max_style_words=3)\n",
    "st_loader = DataLoader(st_dataset, batch_size=16, shuffle=True, num_workers=0, drop_last=True)\n",
    "print(f\"Dataset size: {len(st_dataset)}\")\n",
    "print(f\"Batches: {len(st_loader)}\\n\")\n",
    "\n",
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "st_generator = StyleTransferGenerator(in_channels=2, out_channels=1).to(device)\n",
    "st_discriminator = StyleTransferDiscriminator(in_channels=3).to(device)\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Generator:      {sum(p.numel() for p in st_generator.parameters()):>12,}\")\n",
    "print(f\"Discriminator:  {sum(p.numel() for p in st_discriminator.parameters()):>12,}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Total:          {sum(p.numel() for p in st_generator.parameters()) + sum(p.numel() for p in st_discriminator.parameters()):>12,}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "optimizer_G_st = torch.optim.Adam(st_generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D_st = torch.optim.Adam(st_discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "print(f\"Optimizers initialized (lr={lr})\")\n",
    "print(\" Ready to train!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938662b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Style Transfer GAN\n",
    "\n",
    "num_epochs = 100\n",
    "lambda_l1 = 100  # Weight for L1 loss\n",
    "save_interval = 5\n",
    "checkpoint_dir = 'checkpoints_style_transfer'\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Training history\n",
    "st_history = {\n",
    "    'd_loss': [],\n",
    "    'g_gan_loss': [],\n",
    "    'g_l1_loss': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Starting Style Transfer GAN Training\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs: {num_epochs}\")\n",
    "print(f\"Lambda L1: {lambda_l1}\")\n",
    "print(f\"Batch size: {st_loader.batch_size}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train one epoch\n",
    "        losses = train_style_transfer_epoch(\n",
    "            st_generator, st_discriminator, st_loader,\n",
    "            optimizer_G_st, optimizer_D_st, device, epoch,\n",
    "            lambda_l1=lambda_l1\n",
    "        )\n",
    "        \n",
    "        # Store history\n",
    "        for key in st_history.keys():\n",
    "            st_history[key].append(losses[key])\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs} Summary:\")\n",
    "        print(f\"  D Loss:    {losses['d_loss']:.4f}\")\n",
    "        print(f\"  G GAN:     {losses['g_gan_loss']:.4f}\")\n",
    "        print(f\"  G L1:      {losses['g_l1_loss']:.4f}\")\n",
    "        \n",
    "        # Visualize\n",
    "        if epoch % 5 == 0 or epoch == 1:\n",
    "            print(f\"\\n Visualizing results...\")\n",
    "            visualize_style_transfer_results(st_generator, st_dataset, device, num_samples=4)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if epoch % save_interval == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'generator': st_generator.state_dict(),\n",
    "                'discriminator': st_discriminator.state_dict(),\n",
    "                'optimizer_G': optimizer_G_st.state_dict(),\n",
    "                'optimizer_D': optimizer_D_st.state_dict(),\n",
    "                'history': st_history\n",
    "            }\n",
    "            ckpt_path = os.path.join(checkpoint_dir, f'epoch_{epoch}.pth')\n",
    "            torch.save(checkpoint, ckpt_path)\n",
    "            print(f\" Checkpoint saved: {ckpt_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\" Training completed successfully!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n Training interrupted. Saving checkpoint...\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'generator': st_generator.state_dict(),\n",
    "        'discriminator': st_discriminator.state_dict(),\n",
    "        'optimizer_G': optimizer_G_st.state_dict(),\n",
    "        'optimizer_D': optimizer_D_st.state_dict(),\n",
    "        'history': st_history\n",
    "    }, os.path.join(checkpoint_dir, f'interrupted_epoch_{epoch}.pth'))\n",
    "    print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error during training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc58c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for style transfer\n",
    "\n",
    "def plot_style_transfer_history(history):\n",
    "    \"\"\"Plot training curves\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    epochs = range(1, len(history['d_loss']) + 1)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    axes[0].plot(epochs, history['d_loss'], 'b-', linewidth=2, label='D Loss')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Discriminator Loss', fontsize=14)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(fontsize=10)\n",
    "    \n",
    "    # Generator losses\n",
    "    axes[1].plot(epochs, history['g_gan_loss'], 'r-', linewidth=2, label='GAN Loss')\n",
    "    axes[1].plot(epochs, history['g_l1_loss'], 'g-', linewidth=2, label='L1 Loss')\n",
    "    total_g = [gan + l1 for gan, l1 in zip(history['g_gan_loss'], history['g_l1_loss'])]\n",
    "    axes[1].plot(epochs, total_g, 'purple', linewidth=2, linestyle='--', label='Total G Loss')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1].set_title('Generator Losses', fontsize=14)\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot if history available\n",
    "if 'st_history' in dir() and len(st_history['d_loss']) > 0:\n",
    "    plot_style_transfer_history(st_history)\n",
    "else:\n",
    "    print(\"No training history yet. Run training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eb71f",
   "metadata": {},
   "source": [
    "## Inference: Generate Custom Text with Style Transfer\n",
    "\n",
    "Use your trained model to stylize any text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbe39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_styled_text(generator, style_img, target_text, device):\n",
    "    \"\"\"\n",
    "    Generate styled handwriting for any text.\n",
    "    \n",
    "    Args:\n",
    "        generator: trained StyleTransferGenerator\n",
    "        style_img: PIL Image or tensor (1, 64, 256) - style reference\n",
    "        target_text: string - text to generate\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        generated_img: numpy array (64, 256) in [0, 1]\n",
    "    \"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Prepare style image\n",
    "        if not isinstance(style_img, torch.Tensor):\n",
    "            # Assume PIL Image\n",
    "            if style_img.size != (256, 64):\n",
    "                style_img = style_img.resize((256, 64), Image.LANCZOS)\n",
    "            style_img = T.ToTensor()(style_img) * 2 - 1\n",
    "        \n",
    "        if style_img.dim() == 3:\n",
    "            style_img = style_img.unsqueeze(0)\n",
    "        \n",
    "        style_img = style_img.to(device)\n",
    "        \n",
    "        # Generate plain text image\n",
    "        plain_text_img = render_text_to_image(target_text, size=(64, 256))\n",
    "        plain_text_tensor = T.ToTensor()(plain_text_img) * 2 - 1\n",
    "        plain_text_tensor = plain_text_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        generated = generator(style_img, plain_text_tensor)\n",
    "        \n",
    "        # Convert to numpy [0, 1]\n",
    "        generated_np = (generated.cpu().squeeze().numpy() + 1) / 2\n",
    "    \n",
    "    generator.train()\n",
    "    return generated_np\n",
    "\n",
    "\n",
    "def demo_style_transfer(generator, dataset, device, style_idx=0, custom_texts=None):\n",
    "    \"\"\"\n",
    "    Demo: Apply one style to multiple custom texts\n",
    "    \"\"\"\n",
    "    if custom_texts is None:\n",
    "        custom_texts = [\"hello\", \"world\", \"handwriting\", \"style\"]\n",
    "    \n",
    "    # Get style sample\n",
    "    style_sample = dataset[style_idx]\n",
    "    style_img = style_sample['style_img']\n",
    "    \n",
    "    num_texts = len(custom_texts)\n",
    "    fig, axes = plt.subplots(2, num_texts, figsize=(4 * num_texts, 8))\n",
    "    \n",
    "    # Show style reference\n",
    "    style_np = (style_img.squeeze().numpy() + 1) / 2\n",
    "    for i in range(num_texts):\n",
    "        axes[0, i].imshow(style_np, cmap='gray')\n",
    "        axes[0, i].set_title('Style Reference' if i == num_texts // 2 else '')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Generate for each text\n",
    "    for i, text in enumerate(custom_texts):\n",
    "        generated_np = generate_styled_text(generator, style_img, text, device)\n",
    "        \n",
    "        axes[1, i].imshow(generated_np, cmap='gray')\n",
    "        axes[1, i].set_title(f'\"{text}\"')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Style Transfer: Same Style, Different Texts', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage (uncomment after training)\n",
    "# demo_style_transfer(st_generator, st_dataset, device, style_idx=10, \n",
    "#                     custom_texts=[\"hello\", \"world\", \"test\", \"demo\"])\n",
    "\n",
    "print(\" Inference functions ready!\")\n",
    "print(\"\\nTo generate custom text:\")\n",
    "print(\"  demo_style_transfer(st_generator, st_dataset, device, style_idx=10, custom_texts=['your', 'text'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65514933",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Summary: Two Architectures Implemented\n",
    "\n",
    "### **Approach 1: Embedding-Based Generation (ScrabbleGAN-style)**\n",
    "**Location**: Cells after \"Improved Architecture - ScrabbleGAN Style\"\n",
    "\n",
    "**How it works:**\n",
    "- Encodes style images and text into embeddings\n",
    "- Generator creates images from embeddings using AdaIN\n",
    "- 3-stage training: style encoder  generator  GAN\n",
    "\n",
    "**Pros:**\n",
    "- More flexible (can interpolate styles)\n",
    "- Learns deeper style representations\n",
    "- Writer ID pretraining helps\n",
    "\n",
    "**Cons:**\n",
    "- Complex training (3 stages)\n",
    "- Generator must learn letter shapes from scratch\n",
    "- Less stable initially\n",
    "\n",
    "---\n",
    "\n",
    "### **Approach 2: Style Transfer (Image-to-Image) -  RECOMMENDED**\n",
    "**Location**: Cells after \"Alternative Architecture: Style Transfer Approach\"\n",
    "\n",
    "**How it works:**\n",
    "- **Input 1**: Style reference (real handwriting of 1-3 consecutive words)\n",
    "- **Input 2**: Plain font rendering of target text (structural guide)\n",
    "- **Output**: Plain text transformed to match style\n",
    "- Single-stage UNet-based training\n",
    "\n",
    "**Pros:** \n",
    "- **Much more stable training** - no pretraining needed!\n",
    "- Generator has structural guidance (doesn't learn shapes from scratch)\n",
    "- Simpler architecture, fewer stages\n",
    "- Better initial results\n",
    "- Task is easier: style transfer vs generation\n",
    "\n",
    "**Cons:**\n",
    "- Requires font rendering\n",
    "- Less flexible for style interpolation\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Architectural Differences:**\n",
    "\n",
    "| Aspect | Approach 1 (ScrabbleGAN) | Approach 2 (Style Transfer) |\n",
    "|--------|--------------------------|----------------------------|\n",
    "| **Input** | Text embeddings + style embedding | Style image + plain text image |\n",
    "| **Generator** | Modulated ResBlocks with AdaIN | UNet with skip connections |\n",
    "| **Training Stages** | 3 (pretrain style  pretrain gen  GAN) | 1 (direct GAN training) |\n",
    "| **Structural Guidance** | None | Plain text acts as sketch |\n",
    "| **Stability** | Requires careful tuning | Very stable |\n",
    "| **Initial Quality** | Lower (learns from scratch) | Higher (transfer task) |\n",
    "| **Parameters** | ~30M | ~15M |\n",
    "\n",
    "---\n",
    "\n",
    "### **Which to Use?**\n",
    "\n",
    "**For this project, I recommend Approach 2 (Style Transfer)** because:\n",
    "1.  Much more stable - no multi-stage complexity\n",
    "2.  Better initial results\n",
    "3.  The plain text provides crucial structural guidance\n",
    "4.  Simpler to debug and tune\n",
    "5.  Faster training convergence\n",
    "\n",
    "The style transfer approach treats this as an **image translation task** (like pix2pix), which is proven and stable, rather than trying to generate text from embeddings alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
