{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68a3fe0",
   "metadata": {},
   "source": [
    "# IAM Handwriting Dataset Preparation for CycleGAN\n",
    "\n",
    "This notebook processes the IAM handwriting forms dataset to prepare it for CycleGAN training:\n",
    "1. Extract writer IDs from image filenames\n",
    "2. Split writers into two groups (Domain A and Domain B) for style transfer\n",
    "3. Create train/test splits while preventing data leakage\n",
    "4. Organize images into CycleGAN-compatible folder structure: `trainA/`, `trainB/`, `testA/`, `testB/`\n",
    "\n",
    "**CycleGAN learns to translate between two domains (e.g., Writer Group A â†” Writer Group B handwriting styles)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da78e4",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries\n",
    "\n",
    "Install all necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d2f59",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaad1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63488b22",
   "metadata": {},
   "source": [
    "## Step 3: Define Dataset Path and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef553925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directory containing the IAM dataset\n",
    "base_dir = \"/home/studentiotlab/image_to_image/data/iam_forms_dataset/data\"\n",
    "\n",
    "# Output directory for CycleGAN-formatted dataset\n",
    "output_dir = \"/home/studentiotlab/image_to_image/data/iam_cyclegan\"\n",
    "\n",
    "# Split ratios\n",
    "TRAIN_RATIO = 0.85  # 85% for training\n",
    "TEST_RATIO = 0.15   # 15% for testing\n",
    "\n",
    "# Domain split ratio (how to divide writers into Domain A and B)\n",
    "DOMAIN_A_RATIO = 0.5  # 50% of writers go to Domain A, 50% to Domain B\n",
    "\n",
    "print(f\"Input directory: {base_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Split ratios - Train: {TRAIN_RATIO}, Test: {TEST_RATIO}\")\n",
    "print(f\"Domain split - Domain A: {DOMAIN_A_RATIO*100}%, Domain B: {(1-DOMAIN_A_RATIO)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d477b6",
   "metadata": {},
   "source": [
    "## Step 4: Traverse Dataset and Extract Writer IDs\n",
    "\n",
    "Find all .png files and extract writer ID from each filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ea924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store image paths and writer IDs\n",
    "image_paths = []\n",
    "writer_ids = []\n",
    "\n",
    "# Traverse the directory recursively to find all .png files\n",
    "print(\"Scanning dataset directory for .png files...\")\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.png'):\n",
    "            # Get full absolute path\n",
    "            full_path = os.path.abspath(os.path.join(root, filename))\n",
    "            \n",
    "            # Extract writer ID (part before the first '-')\n",
    "            # Example: a01-000u.png -> a01\n",
    "            writer_id = filename.split('-')[0]\n",
    "            \n",
    "            image_paths.append(full_path)\n",
    "            writer_ids.append(writer_id)\n",
    "\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "print(f\"Example filenames and writer IDs:\")\n",
    "for i in range(min(5, len(image_paths))):\n",
    "    print(f\"  {os.path.basename(image_paths[i])} -> Writer ID: {writer_ids[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82c122",
   "metadata": {},
   "source": [
    "## Step 5: Create Writer Labels CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'image_path': image_paths,\n",
    "    'writer_id': writer_ids\n",
    "})\n",
    "\n",
    "# Save to CSV in the output directory\n",
    "csv_path = os.path.join(output_dir, 'writer_labels.csv')\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create output dir if it doesn't exist\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved to: {csv_path}\")\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nFirst few entries:\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f193c8",
   "metadata": {},
   "source": [
    "## Step 6: Split Writers into Domain A and Domain B\n",
    "\n",
    "For CycleGAN, we need two domains. We'll split writers into two groups to learn style transfer between different handwriting styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique writer IDs\n",
    "unique_writers = df['writer_id'].unique()\n",
    "print(f\"Total unique writers: {len(unique_writers)}\")\n",
    "\n",
    "# First split: Divide writers into Domain A and Domain B (for CycleGAN)\n",
    "domain_A_writers, domain_B_writers = train_test_split(\n",
    "    unique_writers, \n",
    "    test_size=(1 - DOMAIN_A_RATIO), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDomain distribution:\")\n",
    "print(f\"  Domain A writers: {len(domain_A_writers)}\")\n",
    "print(f\"  Domain B writers: {len(domain_B_writers)}\")\n",
    "\n",
    "# Second split: For each domain, split writers into train/test\n",
    "trainA_writers, testA_writers = train_test_split(\n",
    "    domain_A_writers,\n",
    "    test_size=TEST_RATIO,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "trainB_writers, testB_writers = train_test_split(\n",
    "    domain_B_writers,\n",
    "    test_size=TEST_RATIO,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nWriter distribution per split:\")\n",
    "print(f\"  Domain A - Train: {len(trainA_writers)}, Test: {len(testA_writers)}\")\n",
    "print(f\"  Domain B - Train: {len(trainB_writers)}, Test: {len(testB_writers)}\")\n",
    "\n",
    "# Create sets for quick lookup\n",
    "trainA_writer_set = set(trainA_writers)\n",
    "testA_writer_set = set(testA_writers)\n",
    "trainB_writer_set = set(trainB_writers)\n",
    "testB_writer_set = set(testB_writers)\n",
    "\n",
    "# Assign each image to its corresponding split\n",
    "def assign_cyclegan_split(writer_id):\n",
    "    if writer_id in trainA_writer_set:\n",
    "        return 'trainA'\n",
    "    elif writer_id in testA_writer_set:\n",
    "        return 'testA'\n",
    "    elif writer_id in trainB_writer_set:\n",
    "        return 'trainB'\n",
    "    elif writer_id in testB_writer_set:\n",
    "        return 'testB'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df['split'] = df['writer_id'].apply(assign_cyclegan_split)\n",
    "\n",
    "# Count images per split\n",
    "split_counts = df['split'].value_counts()\n",
    "print(f\"\\nImage distribution:\")\n",
    "for split_name in ['trainA', 'testA', 'trainB', 'testB']:\n",
    "    count = split_counts.get(split_name, 0)\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {split_name}: {count} images ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fab4ed",
   "metadata": {},
   "source": [
    "## Step 7: Create CycleGAN Directory Structure\n",
    "\n",
    "Create the folder structure that CycleGAN expects: `trainA/`, `trainB/`, `testA/`, `testB/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CycleGAN directory structure\n",
    "trainA_dir = os.path.join(output_dir, 'trainA')\n",
    "testA_dir = os.path.join(output_dir, 'testA')\n",
    "trainB_dir = os.path.join(output_dir, 'trainB')\n",
    "testB_dir = os.path.join(output_dir, 'testB')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(trainA_dir, exist_ok=True)\n",
    "os.makedirs(testA_dir, exist_ok=True)\n",
    "os.makedirs(trainB_dir, exist_ok=True)\n",
    "os.makedirs(testB_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Created CycleGAN directory structure:\")\n",
    "print(f\"  trainA: {trainA_dir}\")\n",
    "print(f\"  testA: {testA_dir}\")\n",
    "print(f\"  trainB: {trainB_dir}\")\n",
    "print(f\"  testB: {testB_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01dad87",
   "metadata": {},
   "source": [
    "## Step 8: Copy Images to CycleGAN Folders\n",
    "\n",
    "Copy each image to its corresponding domain and split directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fe930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images to their respective split directories\n",
    "print(\"Copying images to CycleGAN directory structure...\")\n",
    "copy_count = {'trainA': 0, 'testA': 0, 'trainB': 0, 'testB': 0}\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    src_path = row['image_path']\n",
    "    split = row['split']\n",
    "    \n",
    "    # Determine destination directory\n",
    "    if split == 'trainA':\n",
    "        dst_dir = trainA_dir\n",
    "    elif split == 'testA':\n",
    "        dst_dir = testA_dir\n",
    "    elif split == 'trainB':\n",
    "        dst_dir = trainB_dir\n",
    "    elif split == 'testB':\n",
    "        dst_dir = testB_dir\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Get filename and create destination path\n",
    "    filename = os.path.basename(src_path)\n",
    "    dst_path = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    # Copy the file\n",
    "    try:\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        copy_count[split] += 1\n",
    "        \n",
    "        # Print progress every 100 images\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"  Processed {idx + 1}/{len(df)} images...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {src_path}: {e}\")\n",
    "\n",
    "print(f\"\\nCopying complete!\")\n",
    "print(f\"Files copied:\")\n",
    "print(f\"  trainA: {copy_count['trainA']}\")\n",
    "print(f\"  testA: {copy_count['testA']}\")\n",
    "print(f\"  trainB: {copy_count['trainB']}\")\n",
    "print(f\"  testB: {copy_count['testB']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cd35d",
   "metadata": {},
   "source": [
    "## Step 9: Display Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90377993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CYCLEGAN DATASET PREPARATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Total statistics\n",
    "print(f\"\\nğŸ“Š Overall Statistics:\")\n",
    "print(f\"  Total images: {len(df)}\")\n",
    "print(f\"  Total unique writers: {len(unique_writers)}\")\n",
    "\n",
    "# Domain distribution\n",
    "print(f\"\\nğŸ¨ Domain Distribution:\")\n",
    "print(f\"  Domain A writers: {len(domain_A_writers)} ({len(domain_A_writers)/len(unique_writers)*100:.1f}%)\")\n",
    "print(f\"  Domain B writers: {len(domain_B_writers)} ({len(domain_B_writers)/len(unique_writers)*100:.1f}%)\")\n",
    "\n",
    "# Writer distribution per split\n",
    "print(f\"\\nğŸ‘¤ Writer Distribution:\")\n",
    "print(f\"  trainA: {len(trainA_writers)} writers\")\n",
    "print(f\"  testA: {len(testA_writers)} writers\")\n",
    "print(f\"  trainB: {len(trainB_writers)} writers\")\n",
    "print(f\"  testB: {len(testB_writers)} writers\")\n",
    "\n",
    "# Image distribution\n",
    "print(f\"\\nğŸ–¼ï¸  Image Distribution:\")\n",
    "for split_name in ['trainA', 'testA', 'trainB', 'testB']:\n",
    "    count = split_counts.get(split_name, 0)\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {split_name}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "# Images per writer statistics\n",
    "print(f\"\\nğŸ“ˆ Images per Writer Statistics:\")\n",
    "writer_image_counts = df.groupby('writer_id').size()\n",
    "print(f\"  Mean images per writer: {writer_image_counts.mean():.2f}\")\n",
    "print(f\"  Median images per writer: {writer_image_counts.median():.0f}\")\n",
    "print(f\"  Min images per writer: {writer_image_counts.min()}\")\n",
    "print(f\"  Max images per writer: {writer_image_counts.max()}\")\n",
    "\n",
    "# Data leakage check\n",
    "print(f\"\\nâœ… Data Leakage Check:\")\n",
    "all_splits = [trainA_writer_set, testA_writer_set, trainB_writer_set, testB_writer_set]\n",
    "split_names = ['trainA', 'testA', 'trainB', 'testB']\n",
    "\n",
    "leakage_found = False\n",
    "for i in range(len(all_splits)):\n",
    "    for j in range(i+1, len(all_splits)):\n",
    "        overlap = all_splits[i].intersection(all_splits[j])\n",
    "        if len(overlap) > 0:\n",
    "            print(f\"  âœ— WARNING: {split_names[i]}-{split_names[j]} overlap: {len(overlap)} writers\")\n",
    "            leakage_found = True\n",
    "\n",
    "if not leakage_found:\n",
    "    print(\"  âœ“ No data leakage detected - all writers are in exactly one split!\")\n",
    "\n",
    "# Sample entries\n",
    "print(f\"\\nğŸ“„ Sample Entries:\")\n",
    "sample_df = df[['image_path', 'writer_id', 'split']].groupby('split').head(2)\n",
    "for split in ['trainA', 'testA', 'trainB', 'testB']:\n",
    "    split_samples = df[df['split'] == split].head(2)\n",
    "    if len(split_samples) > 0:\n",
    "        print(f\"\\n  {split}:\")\n",
    "        for _, row in split_samples.iterrows():\n",
    "            print(f\"    {os.path.basename(row['image_path'])} (writer: {row['writer_id']})\")\n",
    "\n",
    "print(f\"\\nğŸ“ Output Files:\")\n",
    "print(f\"  CSV file: {csv_path}\")\n",
    "print(f\"  CycleGAN dataset: {output_dir}\")\n",
    "print(f\"    â”œâ”€â”€ trainA/ ({copy_count.get('trainA', 0)} images)\")\n",
    "print(f\"    â”œâ”€â”€ testA/ ({copy_count.get('testA', 0)} images)\")\n",
    "print(f\"    â”œâ”€â”€ trainB/ ({copy_count.get('trainB', 0)} images)\")\n",
    "print(f\"    â””â”€â”€ testB/ ({copy_count.get('testB', 0)} images)\")\n",
    "\n",
    "print(f\"\\nğŸš€ Ready for CycleGAN Training!\")\n",
    "print(f\"  Use this command to train:\")\n",
    "print(f\"  DATA_ROOT={output_dir} name=iam_handwriting_model th train.lua\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
