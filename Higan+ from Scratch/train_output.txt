Device: cuda
Output Directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

============================================================
LOADING CHECKPOINT
============================================================
âœ“ Loaded checkpoint from epoch 20
âœ“ Training iterations completed: 130560

Checkpoint keys: ['epoch', 'generator', 'discriminator', 'style_encoder', 'patch_discriminator', 'writer_identifier', 'optimizer_G', 'optimizer_D', 'lr_scheduler_G', 'lr_scheduler_D', 'history', 'iter_count']

--- Training History ---
epoch: 20 epochs recorded
g_loss: 20 epochs recorded
d_loss: 20 epochs recorded
adv_loss: 20 epochs recorded
ctc_loss: 20 epochs recorded
wid_loss: 20 epochs recorded
recn_loss: 20 epochs recorded

============================================================
ANALYZING TRAINING CURVES
============================================================
âœ“ Saved training curves to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_curves.png

--- Training Statistics Summary ---
               final        min        max        avg  improvement
g_loss     28.889342  28.889342  74.070991  35.686412    60.997765
d_loss      0.809803   0.118408   0.809803   0.604940  -423.326148
adv_loss    3.694045   3.694045   6.041302   4.258486    29.278165
ctc_loss    1.209572   1.209572  16.860937   3.109513    92.826185
wid_loss    2.700991   2.685992  11.501977   4.590241    76.517154
recn_loss   0.317497   0.317497   0.381324   0.332063    16.738076
âœ“ Saved statistics to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_statistics.csv

============================================================
CONVERGENCE ANALYSIS
============================================================
âœ“ Saved convergence analysis to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\convergence_analysis.png

--- Convergence Metrics ---
Final G/D Ratio: 35.6745
Avg G/D Ratio (last 5 epochs): 37.0398
âš  Generator is stronger - May indicate mode collapse risk

============================================================
COMPONENT LOSS BREAKDOWN
============================================================
âœ“ Saved component losses to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\component_losses.png

--- Final Component Loss Values ---
Adversarial: 3.694045
CTC (OCR): 1.209572
Writer ID: 2.700991
Reconstruction: 0.317497

============================================================
MODEL STATE ANALYSIS
============================================================

--- Model Components in Checkpoint ---
âœ“ Generator: 3,951,841 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Style Encoder: 148,032 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Patch Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Writer Identifier: 161,396 parameters
  âœ“ All parameters are valid (no NaN/Inf)

============================================================
OPTIMIZER STATE ANALYSIS
============================================================

--- Optimizer G ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

--- Optimizer D ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

============================================================
LEARNING RATE SCHEDULE
============================================================

--- Lr Scheduler G ---
  Last Epoch: 19
  Last LR: [0.0002]

--- Lr Scheduler D ---
  Last Epoch: 19
  Last LR: [0.0002]

============================================================
GENERATING COMPREHENSIVE REPORT
============================================================
======================================================================
HiGAN+ MODEL EVALUATION REPORT
======================================================================

Checkpoint: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\server_files\epoch_20.pth
Epoch: 20
Total Iterations: 130560
Device: cuda

----------------------------------------------------------------------

TRAINING SUMMARY
----------------------------------------------------------------------
Total Epochs Trained: 20

Generator Loss:
  Initial: 74.070991
  Final: 28.889342
  Improvement: 61.00%

Discriminator Loss:
  Initial: 0.154742
  Final: 0.809803
  Improvement: -423.33%

----------------------------------------------------------------------
MODEL COMPONENTS
----------------------------------------------------------------------
Generator: 3,951,841 parameters
Discriminator: 2,368,014 parameters
Style Encoder: 148,032 parameters
Patch Discriminator: 2,368,014 parameters
Writer Identifier: 161,396 parameters

âœ“ Full report saved to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\evaluation_report.txt

============================================================
EVALUATION COMPLETE
============================================================

All results saved to: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

Generated files:
  - training_curves.png
  - convergence_analysis.png
  - component_losses.png
  - training_statistics.csv
  - evaluation_report.txt

============================================================
RECOMMENDATIONS
============================================================
âš  High loss values detected - consider:
  - Reducing learning rate
  - Checking for gradient explosion
  - Reviewing loss weighting

============================================================
C:\Users\PC\AppData\Local\Temp\ipykernel_52772\3704471444.py:17: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.
  if not hasattr(Image, "ANTIALIAS"):
Project path: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch
PyTorch version: 2.8.0+cu129
CUDA available: True
CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU

Using device: cuda
Configuration loaded!
Dataset: iam_word_org
Model: gl_adversarial_model
Batch size: 8
Epochs: 70
Image height: 64
Character width: 32
Current working directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch

Loading dataset...
Training samples: 52231
Test samples: 11170
Training batches: 6528
9.5.0

Batch shape: torch.Size([8, 1, 64, 352])
Label shape: torch.Size([8, 11])
Sample texts: ['destruction', 'Sufolk', 'power', 'While']
Initializing HiGAN+ model components...
âœ“ Generator initialized - Style dim: 32
âœ“ Discriminators initialized (Global + Patch)
âœ“ Style Encoder initialized
âœ“ OCR Recognizer initialized
âœ“ Writer Identifier initialized

--- Model Parameters ---
Generator: 3,935,937
Discriminator: 2,366,145
Patch Discriminator: 2,366,145
Style Encoder: 148,032
Style Backbone: 1,617,328
Recognizer: 2,428,416
Writer ID: 161,396

Total Parameters: 13,023,399

Loading pretrained auxiliary models...
âœ“ Loaded pretrained OCR from ./pretrained/ocr_iam_new.pth
âœ“ Loaded pretrained Writer ID from ./pretrained/wid_iam_new.pth

âœ“ OCR and Writer ID networks frozen for GAN training
Setting up optimizers and loss functions...
âœ“ Optimizers initialized (lr=0.0002)
âœ“ LR Schedulers initialized (linear)
âœ“ Loss functions initialized
âœ“ Lexicon loaded: 465593 words
âœ“ Random distributions initialized

âœ“ Training setup complete!
Starting training...
Training for 70 epochs
Batch size: 8
------------------------------------------------------------
Device: cuda
Output Directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

============================================================
LOADING CHECKPOINT
============================================================
âœ“ Loaded checkpoint from epoch 20
âœ“ Training iterations completed: 130560

Checkpoint keys: ['epoch', 'generator', 'discriminator', 'style_encoder', 'patch_discriminator', 'writer_identifier', 'optimizer_G', 'optimizer_D', 'lr_scheduler_G', 'lr_scheduler_D', 'history', 'iter_count']

--- Training History ---
epoch: 20 epochs recorded
g_loss: 20 epochs recorded
d_loss: 20 epochs recorded
adv_loss: 20 epochs recorded
ctc_loss: 20 epochs recorded
wid_loss: 20 epochs recorded
recn_loss: 20 epochs recorded

============================================================
ANALYZING TRAINING CURVES
============================================================
âœ“ Saved training curves to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_curves.png

--- Training Statistics Summary ---
               final        min        max        avg  improvement
g_loss     28.889342  28.889342  74.070991  35.686412    60.997765
d_loss      0.809803   0.118408   0.809803   0.604940  -423.326148
adv_loss    3.694045   3.694045   6.041302   4.258486    29.278165
ctc_loss    1.209572   1.209572  16.860937   3.109513    92.826185
wid_loss    2.700991   2.685992  11.501977   4.590241    76.517154
recn_loss   0.317497   0.317497   0.381324   0.332063    16.738076
âœ“ Saved statistics to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_statistics.csv

============================================================
CONVERGENCE ANALYSIS
============================================================
âœ“ Saved convergence analysis to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\convergence_analysis.png

--- Convergence Metrics ---
Final G/D Ratio: 35.6745
Avg G/D Ratio (last 5 epochs): 37.0398
âš  Generator is stronger - May indicate mode collapse risk

============================================================
COMPONENT LOSS BREAKDOWN
============================================================
âœ“ Saved component losses to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\component_losses.png

--- Final Component Loss Values ---
Adversarial: 3.694045
CTC (OCR): 1.209572
Writer ID: 2.700991
Reconstruction: 0.317497

============================================================
MODEL STATE ANALYSIS
============================================================

--- Model Components in Checkpoint ---
âœ“ Generator: 3,951,841 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Style Encoder: 148,032 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Patch Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Writer Identifier: 161,396 parameters
  âœ“ All parameters are valid (no NaN/Inf)

============================================================
OPTIMIZER STATE ANALYSIS
============================================================

--- Optimizer G ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

--- Optimizer D ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

============================================================
LEARNING RATE SCHEDULE
============================================================

--- Lr Scheduler G ---
  Last Epoch: 19
  Last LR: [0.0002]

--- Lr Scheduler D ---
  Last Epoch: 19
  Last LR: [0.0002]

============================================================
GENERATING COMPREHENSIVE REPORT
============================================================
======================================================================
HiGAN+ MODEL EVALUATION REPORT
======================================================================

Checkpoint: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\server_files\epoch_20.pth
Epoch: 20
Total Iterations: 130560
Device: cuda

----------------------------------------------------------------------

TRAINING SUMMARY
----------------------------------------------------------------------
Total Epochs Trained: 20

Generator Loss:
  Initial: 74.070991
  Final: 28.889342
  Improvement: 61.00%

Discriminator Loss:
  Initial: 0.154742
  Final: 0.809803
  Improvement: -423.33%

----------------------------------------------------------------------
MODEL COMPONENTS
----------------------------------------------------------------------
Generator: 3,951,841 parameters
Discriminator: 2,368,014 parameters
Style Encoder: 148,032 parameters
Patch Discriminator: 2,368,014 parameters
Writer Identifier: 161,396 parameters

âœ“ Full report saved to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\evaluation_report.txt

============================================================
EVALUATION COMPLETE
============================================================

All results saved to: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

Generated files:
  - training_curves.png
  - convergence_analysis.png
  - component_losses.png
  - training_statistics.csv
  - evaluation_report.txt

============================================================
RECOMMENDATIONS
============================================================
âš  High loss values detected - consider:
  - Reducing learning rate
  - Checking for gradient explosion
  - Reviewing loss weighting

============================================================
Device: cuda
Output Directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results
Samples for evaluation: 1000

============================================================
STEP 1: LOADING MODEL ARCHITECTURES
============================================================
âœ“ Loaded checkpoint from epoch 20

âš  IMPORTANT: You need to initialize your models here!
Add the following code after importing your model classes:

    # Initialize Generator
    generator = Generator(**cfg.GenModel).to(DEVICE)
    generator.load_state_dict(checkpoint['generator'])
    generator.eval()

    # Initialize Style Encoder
    style_encoder = StyleEncoder(**cfg.EncModel).to(DEVICE)
    style_encoder.load_state_dict(checkpoint['style_encoder'])
    style_encoder.eval()

    # Initialize Recognizer (for CER/WER)
    recognizer = Recognizer(**cfg.OcrModel).to(DEVICE)
    recognizer.load_state_dict(checkpoint.get('recognizer', {}))
    recognizer.eval()

    # Initialize Style Backbone
    style_backbone = StyleBackbone(**cfg.StyBackbone).to(DEVICE)
    style_backbone.load_state_dict(checkpoint.get('style_backbone', {}))
    style_backbone.eval()
    

============================================================
STEP 2: LOADING INCEPTION MODEL FOR FID/KID/IS
============================================================
Downloading: "https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth" to C:\Users\PC/.cache\torch\hub\checkpoints\inception_v3_google-0cc3c7bd.pth

  0%|          | 0.00/104M [00:00<?, ?B/s]
  1%|          | 1.25M/104M [00:00<00:08, 12.9MB/s]
  3%|â–Ž         | 3.38M/104M [00:00<00:05, 18.4MB/s]
  6%|â–Œ         | 6.25M/104M [00:00<00:04, 23.5MB/s]
  9%|â–‰         | 9.25M/104M [00:00<00:03, 26.5MB/s]
 11%|â–ˆâ–        | 11.9M/104M [00:00<00:03, 26.7MB/s]
 14%|â–ˆâ–        | 14.6M/104M [00:00<00:03, 27.4MB/s]
 17%|â–ˆâ–‹        | 17.9M/104M [00:00<00:03, 29.2MB/s]
 20%|â–ˆâ–ˆ        | 21.0M/104M [00:00<00:02, 30.3MB/s]
 23%|â–ˆâ–ˆâ–Ž       | 24.0M/104M [00:00<00:02, 30.6MB/s]
 26%|â–ˆâ–ˆâ–Œ       | 27.0M/104M [00:01<00:02, 30.6MB/s]
 29%|â–ˆâ–ˆâ–‰       | 30.2M/104M [00:01<00:02, 31.5MB/s]
 32%|â–ˆâ–ˆâ–ˆâ–      | 33.8M/104M [00:01<00:02, 32.7MB/s]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 36.9M/104M [00:01<00:02, 32.3MB/s]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 40.6M/104M [00:01<00:01, 33.4MB/s]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44.4M/104M [00:01<00:01, 35.0MB/s]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47.8M/104M [00:01<00:01, 34.4MB/s]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51.1M/104M [00:01<00:01, 34.6MB/s]
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54.5M/104M [00:01<00:01, 34.1MB/s]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57.9M/104M [00:01<00:01, 34.2MB/s]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61.2M/104M [00:02<00:01, 32.5MB/s]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64.6M/104M [00:02<00:01, 32.7MB/s]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67.9M/104M [00:02<00:01, 27.7MB/s]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70.9M/104M [00:02<00:01, 28.6MB/s]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 74.0M/104M [00:02<00:01, 29.7MB/s]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77.0M/104M [00:02<00:00, 30.1MB/s]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 80.0M/104M [00:02<00:00, 29.8MB/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 83.0M/104M [00:02<00:00, 30.0MB/s]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86.5M/104M [00:02<00:00, 31.8MB/s]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90.0M/104M [00:03<00:00, 33.2MB/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 93.2M/104M [00:03<00:00, 33.4MB/s]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96.9M/104M [00:03<00:00, 33.6MB/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100M/104M [00:03<00:00, 33.3MB/s] 
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 103M/104M [00:03<00:00, 32.4MB/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104M/104M [00:03<00:00, 31.1MB/s]
âœ“ Inception v3 loaded for FID/KID/IS computation

============================================================
STEP 3: COMPREHENSIVE METRICS EVALUATION
============================================================

--- Metrics Evaluation Pipeline ---

To run full evaluation, you need to:

1. Load your dataset (real images + labels)
2. Generate fake images using the trained generator
3. Extract Inception features from both
4. Calculate all metrics

Example code structure:

# Load test dataset
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# Collect real images
real_images = []
real_labels = []
for batch in tqdm(test_loader, desc='Loading real data'):
    real_images.append(batch['style_imgs'])
    real_labels.extend(batch['labels'])  # Assuming labels are available
    if len(real_images) * BATCH_SIZE >= NUM_SAMPLES:
        break

real_images = torch.cat(real_images)[:NUM_SAMPLES]

# Generate fake images
fake_images = []
fake_labels = []
with torch.no_grad():
    for i in tqdm(range(0, NUM_SAMPLES, BATCH_SIZE), desc='Generating samples'):
        # Sample random texts and styles
        batch_size = min(BATCH_SIZE, NUM_SAMPLES - i)

        # Generate random labels
        # sample_labels = sample_random_labels(batch_size)

        # Generate images
        # z = torch.randn(batch_size, generator.style_dim).to(DEVICE)
        # fake_batch = generator(z, sample_labels, label_lengths)

        # fake_images.append(fake_batch.cpu())
        # fake_labels.extend(decode_labels(sample_labels))

fake_images = torch.cat(fake_images)

# Calculate FID
print('\nCalculating FID...')
mu_real, sigma_real, acts_real = calculate_activation_statistics(
    real_images, inception_model, FID_BATCH_SIZE
)
mu_fake, sigma_fake, acts_fake = calculate_activation_statistics(
    fake_images, inception_model, FID_BATCH_SIZE
)
fid_score = calculate_fid(mu_real, sigma_real, mu_fake, sigma_fake)
metrics_results['FID'] = fid_score
print(f'âœ“ FID Score: {fid_score:.4f}')

# Calculate KID
print('\nCalculating KID...')
kid_mean, kid_std = calculate_kid(acts_real, acts_fake)
metrics_results['KID_mean'] = kid_mean
metrics_results['KID_std'] = kid_std
print(f'âœ“ KID Score: {kid_mean:.4f} Â± {kid_std:.4f}')

# Calculate IS
print('\nCalculating Inception Score...')
is_mean, is_std = calculate_inception_score(acts_fake)
metrics_results['IS_mean'] = is_mean
metrics_results['IS_std'] = is_std
print(f'âœ“ Inception Score: {is_mean:.4f} Â± {is_std:.4f}')

# Calculate CER/WER (requires OCR predictions)
print('\nCalculating CER/WER...')
# pred_texts = run_ocr(fake_images, recognizer)
# cer, wer = calculate_cer_wer(pred_texts, fake_labels)
# metrics_results['CER'] = cer
# metrics_results['WER'] = wer
# print(f'âœ“ CER: {cer:.4f}')
# print(f'âœ“ WER: {wer:.4f}')

# Calculate MSSIM/PSNR (for reconstruction tasks)
print('\nCalculating MSSIM/PSNR...')
# For style transfer: compare generated images with their reconstructions
# mssim_mean, mssim_std, psnr_mean, psnr_std = calculate_image_metrics(
#     real_images[:100], reconstructed_images[:100]
# )
# metrics_results['MSSIM_mean'] = mssim_mean
# metrics_results['MSSIM_std'] = mssim_std
# metrics_results['PSNR_mean'] = psnr_mean
# metrics_results['PSNR_std'] = psnr_std
# print(f'âœ“ MSSIM: {mssim_mean:.4f} Â± {mssim_std:.4f}')
# print(f'âœ“ PSNR: {psnr_mean:.2f} Â± {psnr_std:.2f} dB')


============================================================
DEMO: METRICS STRUCTURE AND BENCHMARKS
============================================================

--- Benchmark Interpretation Guide ---

FID:
  Excellent: < 20
  Good: 20-50
  Fair: 50-100
  Poor: > 100

KID:
  Excellent: < 0.01
  Good: 0.01-0.05
  Fair: 0.05-0.10
  Poor: > 0.10

IS:
  Excellent: > 10
  Good: 5-10
  Fair: 2-5
  Poor: < 2

CER:
  Excellent: < 5%
  Good: 5-10%
  Fair: 10-20%
  Poor: > 20%

WER:
  Excellent: < 10%
  Good: 10-20%
  Fair: 20-35%
  Poor: > 35%

MSSIM:
  Excellent: > 0.90
  Good: 0.80-0.90
  Fair: 0.70-0.80
  Poor: < 0.70

PSNR:
  Excellent: > 30 dB
  Good: 25-30 dB
  Fair: 20-25 dB
  Poor: < 20 dB

============================================================
STEP 4: VISUALIZATION TEMPLATES
============================================================

============================================================
COMPLETE INTEGRATION GUIDE
============================================================

To run full metrics evaluation, integrate this notebook with your training code:

1. **Import your model classes** at the top:
   ```python
   from your_models import Generator, StyleEncoder, Recognizer, etc.
   from your_config import cfg
   from your_dataset import get_dataset, DataLoader
   from your_utils import strLabelConverter, idx_to_words
   ```

2. **Initialize and load models**:
   ```python
   # Generator
   generator = Generator(**cfg.GenModel).to(DEVICE)
   generator.load_state_dict(checkpoint['generator'])
   generator.eval()

   # Style Encoder & Backbone
   style_encoder = StyleEncoder(**cfg.EncModel).to(DEVICE)
   style_encoder.load_state_dict(checkpoint['style_encoder'])
   style_encoder.eval()

   style_backbone = StyleBackbone(**cfg.StyBackbone).to(DEVICE)
   # Load from checkpoint or pretrained

   # Recognizer for OCR
   recognizer = Recognizer(**cfg.OcrModel).to(DEVICE)
   # Load pretrained or from checkpoint
   recognizer.eval()
   ```

3. **Load test dataset**:
   ```python
   test_dataset = get_dataset(cfg.valid.dset_name, cfg.valid.dset_split)
   test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
   ```

4. **Generate samples and calculate metrics**:
   - Follow the pipeline in STEP 3 above
   - Call `plot_metrics_comparison()` for visualization
   - Call `save_metrics_report()` for detailed report

5. **Expected runtime**:
   - FID/KID/IS: ~5-10 minutes for 1000 samples
   - CER/WER: ~2-5 minutes
   - MSSIM/PSNR: ~1-2 minutes
   - Total: ~10-20 minutes

6. **Memory requirements**:
   - GPU: ~4-6 GB for evaluation
   - RAM: ~8 GB for feature extraction


âœ“ Integration guide saved to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\integration_guide.txt

============================================================
SETUP COMPLETE - Ready for Metrics Evaluation
============================================================

Next steps:
1. Import your model classes
2. Initialize models with checkpoint weights
3. Load your test dataset
4. Run the evaluation pipeline
5. Review metrics and visualizations
Project path: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch
PyTorch version: 2.8.0+cu129
CUDA available: True
CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU

Using device: cuda
Configuration loaded!
Dataset: iam_word_org
Model: gl_adversarial_model
Batch size: 8
Epochs: 70
Image height: 64
Character width: 32
Current working directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch

Loading dataset...
Training samples: 52231
Test samples: 11170
Training batches: 6528
9.5.0

Batch shape: torch.Size([8, 1, 64, 320])
Label shape: torch.Size([8, 10])
Sample texts: ['surounded', 'unreliable', 'ratures', 'spear']
Dataset summary (word lengths):
  Train -> samples: 52231, min: 2, max: 19, mean: 4.76, median: 4.00
  Test -> samples: 11170, min: 2, max: 21, mean: 4.44, median: 4.00
Unique writer IDs in training set: 372
Initializing HiGAN+ model components...
âœ“ Generator initialized - Style dim: 32
âœ“ Discriminators initialized (Global + Patch)
âœ“ Style Encoder initialized
âœ“ OCR Recognizer initialized
âœ“ Writer Identifier initialized

--- Model Parameters ---
Generator: 3,935,937
Discriminator: 2,366,145
Patch Discriminator: 2,366,145
Style Encoder: 148,032
Style Backbone: 1,617,328
Recognizer: 2,428,416
Writer ID: 161,396

Total Parameters: 13,023,399

Loading pretrained auxiliary models...
âœ“ Loaded pretrained OCR from ./pretrained/ocr_iam_new.pth
âœ“ Loaded pretrained Writer ID from ./pretrained/wid_iam_new.pth

âœ“ OCR and Writer ID networks frozen for GAN training
Setting up optimizers and loss functions...
âœ“ Optimizers initialized (lr=0.0002)
âœ“ LR Schedulers initialized (linear)
âœ“ Loss functions initialized
âœ“ Lexicon loaded: 465593 words
âœ“ Random distributions initialized

âœ“ Training setup complete!
Starting training/evaluation pipeline...
Target epochs from config: 70
Batch size: 8
------------------------------------------------------------

Loading trained checkpoint for evaluation...
âœ“ Loaded checkpoint 'epoch_20.pth' (epochs trained: 20)
Fine-tuning disabled. Proceeding with evaluation only.
RUN_TRAINING is False; logging redirection skipped.
Device: cuda
Output Directory: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

============================================================
LOADING CHECKPOINT
============================================================
âœ“ Loaded checkpoint from epoch 20
âœ“ Training iterations completed: 130560

Checkpoint keys: ['epoch', 'generator', 'discriminator', 'style_encoder', 'patch_discriminator', 'writer_identifier', 'optimizer_G', 'optimizer_D', 'lr_scheduler_G', 'lr_scheduler_D', 'history', 'iter_count']

--- Training History ---
epoch: 20 epochs recorded
g_loss: 20 epochs recorded
d_loss: 20 epochs recorded
adv_loss: 20 epochs recorded
ctc_loss: 20 epochs recorded
wid_loss: 20 epochs recorded
recn_loss: 20 epochs recorded

============================================================
ANALYZING TRAINING CURVES
============================================================
âœ“ Saved training curves to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_curves.png

--- Training Statistics Summary ---
               final        min        max        avg  improvement
g_loss     28.889342  28.889342  74.070991  35.686412    60.997765
d_loss      0.809803   0.118408   0.809803   0.604940  -423.326148
adv_loss    3.694045   3.694045   6.041302   4.258486    29.278165
ctc_loss    1.209572   1.209572  16.860937   3.109513    92.826185
wid_loss    2.700991   2.685992  11.501977   4.590241    76.517154
recn_loss   0.317497   0.317497   0.381324   0.332063    16.738076
âœ“ Saved statistics to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\training_statistics.csv

============================================================
CONVERGENCE ANALYSIS
============================================================
âœ“ Saved convergence analysis to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\convergence_analysis.png

--- Convergence Metrics ---
Final G/D Ratio: 35.6745
Avg G/D Ratio (last 5 epochs): 37.0398
âš  Generator is stronger - May indicate mode collapse risk

============================================================
COMPONENT LOSS BREAKDOWN
============================================================
âœ“ Saved component losses to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\component_losses.png

--- Final Component Loss Values ---
Adversarial: 3.694045
CTC (OCR): 1.209572
Writer ID: 2.700991
Reconstruction: 0.317497

============================================================
MODEL STATE ANALYSIS
============================================================

--- Model Components in Checkpoint ---
âœ“ Generator: 3,951,841 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Style Encoder: 148,032 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Patch Discriminator: 2,368,014 parameters
  âœ“ All parameters are valid (no NaN/Inf)
âœ“ Writer Identifier: 161,396 parameters
  âœ“ All parameters are valid (no NaN/Inf)

============================================================
OPTIMIZER STATE ANALYSIS
============================================================

--- Optimizer G ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

--- Optimizer D ---
  Parameter Group 0:
    Learning Rate: 0.0002
    Weight Decay: 0
    Beta1: 0.5
    Beta2: 0.999

============================================================
LEARNING RATE SCHEDULE
============================================================

--- Lr Scheduler G ---
  Last Epoch: 19
  Last LR: [0.0002]

--- Lr Scheduler D ---
  Last Epoch: 19
  Last LR: [0.0002]

============================================================
GENERATING COMPREHENSIVE REPORT
============================================================
======================================================================
HiGAN+ MODEL EVALUATION REPORT
======================================================================

Checkpoint: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\server_files\epoch_20.pth
Epoch: 20
Total Iterations: 130560
Device: cuda

----------------------------------------------------------------------

TRAINING SUMMARY
----------------------------------------------------------------------
Total Epochs Trained: 20

Generator Loss:
  Initial: 74.070991
  Final: 28.889342
  Improvement: 61.00%

Discriminator Loss:
  Initial: 0.154742
  Final: 0.809803
  Improvement: -423.33%

----------------------------------------------------------------------
MODEL COMPONENTS
----------------------------------------------------------------------
Generator: 3,951,841 parameters
Discriminator: 2,368,014 parameters
Style Encoder: 148,032 parameters
Patch Discriminator: 2,368,014 parameters
Writer Identifier: 161,396 parameters

âœ“ Full report saved to B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results\evaluation_report.txt

============================================================
EVALUATION COMPLETE
============================================================

All results saved to: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\evaluation_results

Generated files:
  - training_curves.png
  - convergence_analysis.png
  - component_losses.png
  - training_statistics.csv
  - evaluation_report.txt

============================================================
RECOMMENDATIONS
============================================================
âš  High loss values detected - consider:
  - Reducing learning rate
  - Checking for gradient explosion
  - Reviewing loss weighting

============================================================
RUN_TRAINING is False. Using loaded weights without additional training.
âœ“ Training loss curves saved as 'training_losses.png'

Calculating OCR accuracy metrics...

Evaluating OCR:   0%|          | 0/2793 [00:00<?, ?it/s]
Evaluating OCR:   0%|          | 1/2793 [00:01<1:23:22,  1.79s/it]
Evaluating OCR:   0%|          | 2/2793 [00:01<37:54,  1.23it/s]  
Evaluating OCR:   0%|          | 3/2793 [00:02<25:22,  1.83it/s]
Evaluating OCR:   0%|          | 4/2793 [00:02<23:06,  2.01it/s]
Evaluating OCR:   0%|          | 5/2793 [00:02<16:59,  2.73it/s]
Evaluating OCR:   0%|          | 7/2793 [00:02<10:33,  4.40it/s]
Evaluating OCR:   0%|          | 9/2793 [00:03<07:30,  6.19it/s]
Evaluating OCR:   0%|          | 11/2793 [00:03<05:35,  8.30it/s]
Evaluating OCR:   0%|          | 13/2793 [00:03<04:42,  9.83it/s]
Evaluating OCR:   1%|          | 15/2793 [00:03<05:32,  8.36it/s]
Evaluating OCR:   1%|          | 18/2793 [00:03<04:00, 11.56it/s]
Evaluating OCR:   1%|          | 20/2793 [00:04<05:11,  8.90it/s]
Evaluating OCR:   1%|          | 23/2793 [00:04<03:55, 11.76it/s]
Evaluating OCR:   1%|          | 26/2793 [00:04<03:16, 14.09it/s]
Evaluating OCR:   1%|          | 29/2793 [00:04<02:51, 16.15it/s]
Evaluating OCR:   1%|          | 32/2793 [00:04<02:32, 18.05it/s]
Evaluating OCR:   1%|â–         | 35/2793 [00:04<02:15, 20.40it/s]
Evaluating OCR:   1%|â–         | 38/2793 [00:04<02:03, 22.31it/s]
Evaluating OCR:   1%|â–         | 41/2793 [00:04<01:56, 23.53it/s]
Evaluating OCR:   2%|â–         | 44/2793 [00:05<01:53, 24.16it/s]
Evaluating OCR:   2%|â–         | 48/2793 [00:05<01:45, 26.11it/s]
Evaluating OCR:   2%|â–         | 50/2793 [00:05<04:45,  9.61it/s]

============================================================
OCR Performance Metrics:
  Character Error Rate (CER): 2.96%
  Word Error Rate (WER): 10.00%
  Character Accuracy: 97.04%
  Word Accuracy: 90.00%
============================================================


Calculating image quality metrics...

Generating samples for metrics:   0%|          | 0/2793 [00:00<?, ?it/s]
Generating samples for metrics:   0%|          | 5/2793 [00:00<01:07, 41.10it/s]
Generating samples for metrics:   0%|          | 10/2793 [00:00<01:27, 31.96it/s]
Generating samples for metrics:   1%|          | 14/2793 [00:00<01:26, 32.06it/s]
Generating samples for metrics:   1%|          | 19/2793 [00:00<01:18, 35.32it/s]
Generating samples for metrics:   1%|          | 24/2793 [00:00<01:14, 37.23it/s]
Generating samples for metrics:   1%|          | 25/2793 [00:00<01:17, 35.63it/s]
Error calculating quality metrics: Sizes of tensors must match except in dimension 0. Expected size 352 but got size 288 for tensor number 1 in the list.

Computing advanced quality metrics (FID, KID, IS, MSSIM, PSNR)...

  0%|          | 0/20 [00:00<?, ?it/s]
  5%|â–Œ         | 1/20 [00:00<00:02,  6.67it/s]
 20%|â–ˆâ–ˆ        | 4/20 [00:00<00:01, 15.06it/s]
 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:00<00:00, 14.77it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:00<00:00, 15.62it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:01<00:00,  9.47it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:01<00:00, 12.54it/s]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:01<00:00, 13.86it/s]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:01<00:00, 14.38it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 15.62it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 13.67it/s]

  0%|          | 0/20 [00:00<?, ?it/s]
 10%|â–ˆ         | 2/20 [00:00<00:01, 16.04it/s]
 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:00<00:00, 18.01it/s]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:00<00:00, 20.80it/s]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:00<00:00, 20.71it/s]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:00<00:00, 20.48it/s]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:00<00:00, 19.36it/s]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:00<00:00, 19.30it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:01<00:00, 16.58it/s]
Warning: subset_size is bigger than len(codes_g). [sub:200  code_g:80]
  FID: 38.0292
  KID: 0.7314
  Inception Score (real): 1.4397
  Inception Score (generated): 1.4271

  0%|          | 0/20 [00:00<?, ?it/s]gen_img_len 320 != src_img_len 445

  0%|          | 0/20 [00:00<?, ?it/s]
  âš ï¸ MSSIM/PSNR computation failed: Input images must have the same dimensions.
Evaluated 80 generated samples across 20 batches.
Models ready for inference!
âœ“ Style-guided generation complete!
âœ“ Random style generation complete!
âœ“ Style interpolation complete!
âœ“ Same-style multi-text generation complete!
=== Custom Style Transfer Demo ===

Reference image text: "w"
Reference image size: torch.Size([1, 1, 64, 160])

Generating 5 custom texts in the reference style...
Extracted style vector: torch.Size([1, 32])
Generated images: torch.Size([5, 1, 64, 736])

âœ“ Custom style transfer complete!
âœ“ Saved result to: inference_custom_style_transfer.png
================================================================================
HiGAN+ MODEL EVALUATION SUMMARY
================================================================================

ðŸ“Š CONFIGURATION:
  â€¢ Dataset: iam_word_org
  â€¢ Epochs Available: 20
  â€¢ Batch Size: 8
  â€¢ Learning Rate: 0.0002
  â€¢ Style Dimension: 32
  â€¢ VAE Mode: True
  â€¢ Checkpoint Source: B:\College\DL\handwriting_autocomplete_system\Higan+ from Scratch\server_files\epoch_20.pth
  â€¢ Additional Training This Session: No

ðŸ—ï¸ MODEL ARCHITECTURE:
  â€¢ Generator Parameters: 3,935,937
  â€¢ Discriminator Parameters: 2,366,145
  â€¢ Style Encoder Parameters: 148,032
  â€¢ Total Trainable Parameters: 6,450,114

ðŸ“ˆ MOST RECENT TRAINING LOGS:
  â€¢ Last Epoch Logged: 20
  â€¢ Generator Loss: 28.8893
  â€¢ Discriminator Loss: 0.8098
  â€¢ Adversarial Loss: 3.6940
  â€¢ CTC Loss: 1.2096

ðŸŽ¯ EVALUATION METRICS:
  â€¢ Character Error Rate (CER): 2.96%
  â€¢ Word Error Rate (WER): 10.00%
  â€¢ Character Accuracy: 97.04%
  â€¢ Word Accuracy: 90.00%
  â€¢ Simple image metrics unavailable.
  â€¢ FID: 38.0292
  â€¢ KID: 0.7314
  â€¢ Inception Score (Real): 1.4397
  â€¢ Inception Score (Generated): 1.4271
  â€¢ MSSIM/PSNR metrics unavailable.

âœ… GENERATED OUTPUTS:
  â€¢ training_losses.png - Training loss curves
  â€¢ inference_style_guided.png - Style-guided generation
  â€¢ inference_random_style.png - Random style generation
  â€¢ inference_interpolation.png - Style interpolation
  â€¢ inference_same_style.png - Same style, different texts
  â€¢ inference_custom_style_transfer.png - Reference style transfer

ðŸ”¬ MODEL CAPABILITIES:
  âœ“ Generate realistic handwritten text images
  âœ“ Control writing style through style vectors
  âœ“ Copy style from reference images
  âœ“ Generate arbitrary text content
  âœ“ Smooth style interpolation
  âœ“ Maintain text readability (OCR accuracy)

================================================================================
âœ¨ Evaluation complete!
================================================================================
âœ“ Model saved to: models\higanplus_trained.pth
  File size: 40.02 MB
âœ“ Configuration saved to: models\training_config.json
================================================================================
HiGAN+ MODEL EVALUATION SUMMARY
================================================================================

ðŸ“Š CONFIGURATION:
  â€¢ Dataset: iam_word_org
  â€¢ Epochs Available: 20
  â€¢ Batch Size: 8
  â€¢ Learning Rate: 0.0002
  â€¢ Style Dimension: 32
  â€¢ VAE Mode: True
  â€¢ Checkpoint Source: models\higanplus_trained.pth
  â€¢ Additional Training This Session: No

ðŸ—ï¸ MODEL ARCHITECTURE:
  â€¢ Generator Parameters: 3,935,937
  â€¢ Discriminator Parameters: 2,366,145
  â€¢ Style Encoder Parameters: 148,032
  â€¢ Total Trainable Parameters: 6,450,114

ðŸ“ˆ MOST RECENT TRAINING LOGS:
  â€¢ Last Epoch Logged: 20
  â€¢ Generator Loss: 28.8893
  â€¢ Discriminator Loss: 0.8098
  â€¢ Adversarial Loss: 3.6940
  â€¢ CTC Loss: 1.2096

ðŸŽ¯ EVALUATION METRICS:
  â€¢ Character Error Rate (CER): 2.96%
  â€¢ Word Error Rate (WER): 10.00%
  â€¢ Character Accuracy: 97.04%
  â€¢ Word Accuracy: 90.00%
  â€¢ Simple image metrics unavailable.
  â€¢ FID: 38.0292
  â€¢ KID: 0.7314
  â€¢ Inception Score (Real): 1.4397
  â€¢ Inception Score (Generated): 1.4271
  â€¢ MSSIM/PSNR metrics unavailable.

âœ… GENERATED OUTPUTS:
  â€¢ training_losses.png - Training loss curves
  â€¢ inference_style_guided.png - Style-guided generation
  â€¢ inference_random_style.png - Random style generation
  â€¢ inference_interpolation.png - Style interpolation
  â€¢ inference_same_style.png - Same style, different texts
  â€¢ inference_custom_style_transfer.png - Reference style transfer

ðŸ”¬ MODEL CAPABILITIES:
  âœ“ Generate realistic handwritten text images
  âœ“ Control writing style through style vectors
  âœ“ Copy style from reference images
  âœ“ Generate arbitrary text content
  âœ“ Smooth style interpolation
  âœ“ Maintain text readability (OCR accuracy)

================================================================================
âœ¨ Evaluation complete!
================================================================================
